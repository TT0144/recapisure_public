#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
recapisure - Professional Japanese Text Summarization Web Application

é«˜æ€§èƒ½æ—¥æœ¬èªè¦ç´„Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - Apertus AIçµ±åˆç‰ˆ
æ©Ÿèƒ½: é•·æ–‡è¦ç´„ã€çŸ­æ–‡å±•é–‹ã€URLè¨˜äº‹è¦ç´„ã€ãƒãƒ«ãƒãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œ
"""

import os
import sys
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# OpenMPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®é‡è¤‡åˆæœŸåŒ–è­¦å‘Šã‚’å›é¿
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¼·åˆ¶è¨­å®šï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')
if sys.stderr.encoding != 'utf-8':
    sys.stderr.reconfigure(encoding='utf-8')
os.environ['PYTHONIOENCODING'] = 'utf-8'
import logging
import json
import time
import uuid
import asyncio
from datetime import datetime
from pathlib import Path
from urllib.parse import urlparse
from typing import Dict, Any, List
import requests
import re
import hashlib
from functools import wraps

# PDFå‡¦ç†
import PyPDF2
import pdfplumber
import sqlite3

# Flaské–¢é€£
from flask import Flask, render_template, request, jsonify, session, flash, redirect, url_for
from flask_socketio import SocketIO, emit
from werkzeug.utils import secure_filename

# ç‹¬è‡ªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from config import config
from services.huggingface_service import get_hf_service
from services.kaggle_ai_client import KaggleAIClient  # â­ Kaggleçµ±åˆ
from models.processing import ProcessingResult, ProcessingType, ProcessingStatus, ProcessingRequest
from database import get_db

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OCRå‡¦ç†ç”¨ï¼ˆloggerã®å¾Œã«é…ç½®ï¼‰
try:
    from pdf2image import convert_from_path
    import pytesseract
    from PIL import Image
    OCR_AVAILABLE = True
    logger.info("âœ… OCRæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™ï¼ˆpytesseract + pdf2imageï¼‰")
except ImportError:
    OCR_AVAILABLE = False
    logger.warning("âš ï¸ OCRæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚pip install pytesseract pdf2image Pillow")

# è¨­å®š(æ—§Config ã‚¯ãƒ©ã‚¹ã¯ config.py ã«ç§»è¡Œ)
class Config:
    """ä¸‹ä½äº’æ›æ€§ã®ãŸã‚ã®è¨­å®šã‚¯ãƒ©ã‚¹"""
    SECRET_KEY = config.secret_key
    MAX_CONTENT_LENGTH = config.max_content_length
    UPLOAD_FOLDER = config.upload_folder
    MAX_TEXT_LENGTH = config.max_text_length
    MAX_URL_CONTENT_LENGTH = config.max_url_content_length
    REQUEST_TIMEOUT = config.request_timeout
    ALLOWED_EXTENSIONS = config.allowed_extensions

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def allowed_file(filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯"""
    return '.' in filename and Path(filename).suffix.lower() in Config.ALLOWED_EXTENSIONS

def _fix_ocr_garbled_text(text: str) -> str:
    """
    OCRã§æ–‡å­—åŒ–ã‘ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿®æ­£
    
    Args:
        text: OCRã§æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        ä¿®æ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    import re
    
    # ã‚ˆãã‚ã‚‹æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿®æ­£
    replacements = {
        # Unicodeæ–‡å­—åŒ–ã‘ï¼ˆã‚ˆãè¦‹ã‚‰ã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        'à¼Š': 'åŒº',
        'à»ƒ': 'è¥¿',
        'à»­': 'åŒ—',
        'á†¶': 'å‚',
        'á»ˆ': 'æ°´',
        'á®¾': 'æ±',
        'â„¿': 'ç˜',
        'ã¡²': 'é ˆ',
        'â˜»': 'ç£¨',
        'à­°': 'ä¸­',
        'áŠ¸': 'å¤®',
        'à¶»á—œ': 'å…µåº«',
        'à¶»á—œà¼Š': 'å…µåº«åŒº',
        'ã›—â£': 'é•·ç”°',
        'â–²': '',  # è¨˜å·é™¤å»
        'ã€ˆ': '',
        'ã€‰': '',
        
        # æ•°å­—ãƒ»è¨˜å·ã®æ–‡å­—åŒ–ã‘
        'ã¸«': 'âˆ’',
        'Ï¨': 'â… ',
        'Ï©': 'â…¡',
        'Ïª': 'â…¢',
        
        # ã‚ˆãã‚ã‚‹èª¤èªè­˜
        'ã™ã™à¼Š': 'é ˆç£¨åŒº',
        'à»ƒà¼Š': 'è¥¿åŒº',
        'à»­à¼Š': 'åŒ—åŒº',
        'á†¶á»ˆà¼Š': 'å‚æ°´åŒº',
        'á®¾â„¿à¼Š': 'æ±ç˜åŒº',
        'ã¡²â˜»à¼Š': 'é ˆç£¨åŒº',
        'â„¿à¼Š': 'ç˜åŒº',
        'à­°áŠ¸à¼Š': 'ä¸­å¤®åŒº',
        'à¶»á—œà¼Š': 'å…µåº«åŒº',
        'ã›—â£à¼Š': 'é•·ç”°åŒº',
    }
    
    for wrong, correct in replacements.items():
        text = text.replace(wrong, correct)
    
    # ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'^\s+|\s+$', '', text, flags=re.MULTILINE)
    
    return text

def extract_text_with_ocr(file_path):
    """
    OCRã‚’ä½¿ç”¨ã—ã¦PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆç”»åƒPDFå¯¾å¿œï¼‰
    
    Args:
        file_path: PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        str: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not OCR_AVAILABLE:
        raise ValueError("OCRæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚pip install pytesseract pdf2image Pillow ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    
    try:
        logger.info("ğŸ” OCRå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # PDFã‚’ç”»åƒã«å¤‰æ›
        logger.info("ğŸ“„ PDFã‚’ç”»åƒã«å¤‰æ›ä¸­...")
        images = convert_from_path(file_path, dpi=300)  # 300dpiã§é«˜å“è³ª
        total_pages = len(images)
        logger.info(f"ğŸ“„ {total_pages}ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        
        extracted_pages = []
        
        for page_num, image in enumerate(images, 1):
            try:
                logger.info(f"ğŸ” ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã‚’OCRå‡¦ç†ä¸­...")
                
                # Tesseract OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                # â­ æ—¥æœ¬èªå„ªå…ˆ + è‹±èªã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                try:
                    # ã¾ãšæ—¥æœ¬èª+è‹±èªã§è©¦è¡Œ
                    text = pytesseract.image_to_string(
                        image,
                        lang='jpn+eng',  # æ—¥æœ¬èªã¨è‹±èª
                        config='--psm 1 --oem 1'  # è‡ªå‹•ãƒšãƒ¼ã‚¸ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ + LSTMã‚¨ãƒ³ã‚¸ãƒ³
                    )
                except Exception as lang_error:
                    logger.warning(f"âš ï¸ æ—¥æœ¬èªOCRãŒå¤±æ•—ã€è‹±èªã®ã¿ã§å†è©¦è¡Œ: {lang_error}")
                    # æ—¥æœ¬èªãŒä½¿ãˆãªã„å ´åˆã¯è‹±èªã®ã¿
                    text = pytesseract.image_to_string(
                        image,
                        lang='eng',
                        config='--psm 1 --oem 1'
                    )
                
                if text and text.strip():
                    # â­ OCRã®æ–‡å­—åŒ–ã‘ã‚’å¾Œå‡¦ç†ã§ä¿®æ­£
                    text = _fix_ocr_garbled_text(text)
                    extracted_pages.append(f"â”â”â”â”â” ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} (OCR) â”â”â”â”â”\n{text}")
                    logger.info(f"âœ… ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} OCRå®Œäº† ({len(text)} æ–‡å­—)")
                else:
                    logger.warning(f"âš ï¸ ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    
            except Exception as e:
                logger.error(f"âŒ ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã®OCRå‡¦ç†ã«å¤±æ•—: {e}")
                continue
        
        if extracted_pages:
            result = "\n\n".join(extracted_pages)
            logger.info(f"ğŸ‰ OCRå‡¦ç†å®Œäº†: {len(extracted_pages)}/{total_pages} ãƒšãƒ¼ã‚¸æŠ½å‡ºæˆåŠŸ")
            return result
        else:
            raise ValueError("OCRå‡¦ç†ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
    except Exception as e:
        logger.error(f"âŒ OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        raise ValueError(f"OCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


def extract_text_from_image(file_path):
    """
    â­ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPNG, JPGç­‰ï¼‰ã‹ã‚‰OCRã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    
    Args:
        file_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆPath or strï¼‰
    
    Returns:
        str: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not OCR_AVAILABLE:
        raise ValueError("OCRæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚pip install pytesseract Pillow ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    
    try:
        logger.info(f"ğŸ–¼ï¸ ç”»åƒOCRå‡¦ç†ã‚’é–‹å§‹: {file_path}")
        
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = Image.open(file_path)
        
        # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’ç¢ºèª
        width, height = image.size
        logger.info(f"ğŸ“ ç”»åƒã‚µã‚¤ã‚º: {width}x{height} pixels")
        
        # ç”»åƒãŒå°ã•ã™ãã‚‹å ´åˆã¯æ‹¡å¤§
        if width < 800 or height < 600:
            scale = max(800 / width, 600 / height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            logger.info(f"ğŸ“ ç”»åƒã‚’æ‹¡å¤§: {new_width}x{new_height}")
        
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ï¼ˆOCRç²¾åº¦å‘ä¸Šï¼‰
        if image.mode != 'L':
            image = image.convert('L')
        
        # Tesseract OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        try:
            # ã¾ãšæ—¥æœ¬èª+è‹±èªã§è©¦è¡Œ
            text = pytesseract.image_to_string(
                image,
                lang='jpn+eng',
                config='--psm 3 --oem 1'  # å®Œå…¨è‡ªå‹•ãƒšãƒ¼ã‚¸ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ + LSTMã‚¨ãƒ³ã‚¸ãƒ³
            )
        except Exception as lang_error:
            logger.warning(f"âš ï¸ æ—¥æœ¬èªOCRãŒå¤±æ•—ã€è‹±èªã®ã¿ã§å†è©¦è¡Œ: {lang_error}")
            text = pytesseract.image_to_string(
                image,
                lang='eng',
                config='--psm 3 --oem 1'
            )
        
        if text and text.strip():
            # æ–‡å­—åŒ–ã‘ä¿®æ­£
            text = _fix_ocr_garbled_text(text)
            # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            text = clean_text(text)
            logger.info(f"âœ… ç”»åƒOCRå®Œäº†: {len(text)} æ–‡å­—ã‚’æŠ½å‡º")
            return text
        else:
            raise ValueError("ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
    except Exception as e:
        logger.error(f"âŒ ç”»åƒOCRã‚¨ãƒ©ãƒ¼: {e}")
        raise ValueError(f"ç”»åƒOCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


def clean_pdf_text(text):
    """
    PDFã‹ã‚‰æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    - ãƒšãƒ¼ã‚¸ç•ªå·ã€éå‰°ãªæ”¹è¡Œã€è¨˜å·ã®ç¾…åˆ—ãªã©ã‚’é™¤å»
    """
    if not text:
        return ""
    
    import re
    
    # ãƒ‡ãƒãƒƒã‚°: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
    sample = text[:300] if len(text) > 300 else text
    logger.info(f"ğŸ” PDFæŠ½å‡ºç›´å¾Œ ({len(text)}æ–‡å­—): {repr(sample)}")
    
    # 1. CIDæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: (cid:12255)ï¼‰ã‚’é™¤å»
    text = re.sub(r'\(cid:\d+\)', '', text)
    
    # 2. ãƒšãƒ¼ã‚¸ç•ªå·ã‚’é™¤å»ï¼ˆä¾‹: -62-, -64-, -65- ãªã©ï¼‰
    text = re.sub(r'-\d+-', ' ', text)
    
    # 3. è¨˜å·ã®ç¾…åˆ—ã‚’é™¤å»ï¼ˆâ—â—â–¼â–²â– â–¡â—†â—‡ãŒ3å€‹ä»¥ä¸Šé€£ç¶šï¼‰
    text = re.sub(r'[â—â—â–¼â–²â– â–¡â—†â—‡â—‹]{3,}', ' ', text)
    
    # 4. åŒºåˆ‡ã‚Šç·šã‚’é™¤å»ï¼ˆãƒã‚¤ãƒ•ãƒ³ã€ã‚¤ã‚³ãƒ¼ãƒ«ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ãŒ5å€‹ä»¥ä¸Šé€£ç¶šï¼‰
    text = re.sub(r'[-=_]{5,}', ' ', text)
    
    # 5. ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã®ç¾…åˆ—ã‚’é™¤å»ï¼ˆæ•°å­—%ãŒé€£ç¶šï¼‰
    text = re.sub(r'(?:\d+%\s*){5,}', ' ', text)
    
    # 6. å˜ç‹¬ã®è¨˜å·ã‚’é™¤å»ï¼ˆå‰å¾Œã«ç©ºç™½ãŒã‚ã‚‹è¨˜å·1æ–‡å­—ï¼‰
    text = re.sub(r'\s[â—â–¼â–²â– â–¡â—†â—‡â—‹â—]\s', ' ', text)
    
    # 7. è¡Œé ­ã®è¨˜å·ã‚’é™¤å»
    text = re.sub(r'^[â—â–¼â–²â– â–¡â—†â—‡â—‹â—ãƒ»]\s*', '', text, flags=re.MULTILINE)
    
    # 8. å›³è¡¨è¨˜å·ã‚’é™¤å»ï¼ˆ(å›³1)ã€(è¡¨2)ã€[å›³3]ã€â€»ãªã©ï¼‰
    text = re.sub(r'[(\[ï¼ˆ](?:å›³|è¡¨|å†™çœŸ|è³‡æ–™|ã‚°ãƒ©ãƒ•)\d*[)\]ï¼‰]', '', text)
    text = re.sub(r'â€»+', '', text)
    
    # 9. ç« ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»ï¼ˆI-IIã€II-Iã€I.ã€II.ãªã©ï¼‰
    text = re.sub(r'\b[IVX]+-[IVX]+\b', '', text)
    text = re.sub(r'\b[IVX]+\.\b', '', text)
    text = re.sub(r'\b[IVX]+âˆ’[IVX]+\b', '', text)  # å…¨è§’ãƒ€ãƒƒã‚·ãƒ¥
    
    # 10. æ‹¬å¼§å†…ã®è£œè¶³æƒ…å ±ã‚’é™¤å»ï¼ˆâ€»ã€œï¼‰ãªã©
    text = re.sub(r'[ï¼ˆ(][â€»ï¼Š][^)ï¼‰]*[)ï¼‰]', '', text)
    
    # 11. æ³¢ç·šã‚„çŸ¢å°è¨˜å·ã‚’é™¤å»
    text = re.sub(r'[ã€œï½â†’â‡’â‡¨â¡â–¶â–º]', ' ', text)
    
    # 12. æ‹¬å¼§ã ã‘ãŒæ®‹ã£ãŸå ´åˆã‚’é™¤å»
    text = re.sub(r'[ï¼ˆ()\[\]ï¼‰]+', '', text)
    
    # 13. PDFãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«ã‚ˆã‚‹ä¸è‡ªç„¶ãªæ”¹è¡Œã‚’é™¤å»
    # æ—¥æœ¬èªã®æ–‡ä¸­ã§ã®æ”¹è¡Œï¼ˆå¥èª­ç‚¹ä»¥å¤–ã§çµ‚ã‚ã‚‹è¡Œã®æ”¹è¡Œï¼‰ã‚’é™¤å»
    # ã“ã‚Œã«ã‚ˆã‚ŠPDFã®å·¦æƒãˆã§ç™ºç”Ÿã™ã‚‹æ”¹è¡Œã‚’è‡ªç„¶ãªãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
    text = re.sub(r'(?<=[^\nã€‚ï¼.!ï¼?ï¼Ÿã€ï¼Œ,\n])\n(?=[^\n\s])', '', text)
    
    # 14. åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚„ã‚¿ãƒ–ã®é€£ç¶šã‚’1ã¤ã®ã‚¹ãƒšãƒ¼ã‚¹ã«çµ±ä¸€
    text = re.sub(r'[ \t]+', ' ', text)
    
    # 15. 3ã¤ä»¥ä¸Šé€£ç¶šã™ã‚‹æ”¹è¡Œã‚’2ã¤ã«çµ±ä¸€
    text = re.sub(r'\n{3,}', '\n\n', text)

    # 16. è¡Œé ­ãƒ»è¡Œæœ«ã®ç©ºç™½ã‚’å‰Šé™¤
    lines = [line.strip() for line in text.split('\n')]
    text = '\n'.join(lines)

    # 17. ç©ºè¡ŒãŒ2ã¤ä»¥ä¸Šé€£ç¶šã™ã‚‹å ´åˆã¯1ã¤ã«çµ±ä¸€
    text = re.sub(r'\n\n+', '\n\n', text)

    # 18. ç©ºè¡Œã ã‘ã®è¡Œã‚’å‰Šé™¤
    lines = [line for line in text.split('\n') if line.strip()]
    text = '\n'.join(lines)    # ãƒ‡ãƒãƒƒã‚°: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    sample_after = text[:300] if len(text) > 300 else text
    logger.info(f"âœ… ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ ({len(text)}æ–‡å­—): {repr(sample_after)}")
    
    return text.strip()


def is_garbled_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆãŒæ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹ã‹ã‚’æ¤œå‡º
    
    Args:
        text: ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        bool: æ–‡å­—åŒ–ã‘ã—ã¦ã„ã‚‹å ´åˆTrue
    """
    if not text or len(text) < 10:
        return False
    
    # ã‚µãƒ³ãƒ—ãƒ«æ–‡å­—ã‚’å–å¾—ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰
    sample = text[:500]
    
    # æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒãƒ™ãƒƒãƒˆæ–‡å­—ãƒ»ãƒ©ã‚ªã‚¹æ–‡å­—ãªã©ï¼ˆPDFãƒ•ã‚©ãƒ³ãƒˆå•é¡Œï¼‰
    garbled_chars = 0
    for char in sample:
        code = ord(char)
        # ãƒãƒ™ãƒƒãƒˆæ–‡å­— (U+0F00-0FFF)
        if 0x0F00 <= code <= 0x0FFF:
            garbled_chars += 1
        # ãƒ©ã‚ªã‚¹æ–‡å­— (U+0E80-0EFF)
        elif 0x0E80 <= code <= 0x0EFF:
            garbled_chars += 1
        # ãƒ‡ãƒ¼ãƒ´ã‚¡ãƒŠãƒ¼ã‚¬ãƒªãƒ¼æ–‡å­— (U+0900-097F)
        elif 0x0900 <= code <= 0x097F:
            garbled_chars += 1
        # ãƒ™ãƒ³ã‚¬ãƒ«æ–‡å­— (U+0980-09FF)
        elif 0x0980 <= code <= 0x09FF:
            garbled_chars += 1
        # ãƒŸãƒ£ãƒ³ãƒãƒ¼æ–‡å­— (U+1000-109F)
        elif 0x1000 <= code <= 0x109F:
            garbled_chars += 1
        # ãƒãƒ³ã‚°ãƒ«äº’æ›Jamo (U+3130-318F)
        elif 0x3130 <= code <= 0x318F:
            garbled_chars += 1
    
    # æ–‡å­—åŒ–ã‘æ–‡å­—ãŒ10%ä»¥ä¸Šå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
    garbled_ratio = garbled_chars / len(sample)
    if garbled_ratio > 0.1:
        logger.warning(f"âš ï¸ æ–‡å­—åŒ–ã‘æ¤œå‡º: {garbled_ratio*100:.1f}% ({garbled_chars}/{len(sample)}æ–‡å­—)")
        return True
    
    # æ–‡å­—åŒ–ã‘ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ—¥æœ¬èªPDFãªã®ã«æ—¥æœ¬èªæ–‡å­—ãŒå°‘ãªã™ãã‚‹
    japanese_chars = 0
    for char in sample:
        code = ord(char)
        # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—
        if (0x3040 <= code <= 0x309F) or (0x30A0 <= code <= 0x30FF) or (0x4E00 <= code <= 0x9FFF):
            japanese_chars += 1
    
    japanese_ratio = japanese_chars / len(sample)
    
    # æ—¥æœ¬èªæ–‡å­—ãŒ5%æœªæº€ã®å ´åˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åãªã©ã‹ã‚‰æ—¥æœ¬èªPDFã¨æ¨å®šã•ã‚Œã‚‹å ´åˆï¼‰
    if japanese_ratio < 0.05:
        logger.warning(f"âš ï¸ æ—¥æœ¬èªæ–‡å­—ãŒå°‘ãªã™ãã¾ã™: {japanese_ratio*100:.1f}% - ç”»åƒPDFã®å¯èƒ½æ€§")
        # ã“ã®ã‚±ãƒ¼ã‚¹ã¯æ–‡å­—åŒ–ã‘ã§ã¯ãªãç”»åƒPDFã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
        # ä»–ã®æ¡ä»¶ã‚‚ç¢ºèª
        if garbled_chars > 0:
            return True
    
    return False


def extract_text_from_pdf(file_path):
    """
    PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆå…¨ãƒšãƒ¼ã‚¸å¯¾å¿œãƒ»æ–‡å­—åŒ–ã‘å¯¾ç­–ãƒ»OCRå¯¾å¿œç‰ˆï¼‰
    
    å…¨ãƒšãƒ¼ã‚¸ã‹ã‚‰ç¢ºå®Ÿã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€ãƒšãƒ¼ã‚¸æƒ…å ±ã‚‚å«ã‚ã¦è¿”ã™
    é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§å¤±æ•—ã—ãŸå ´åˆã€è‡ªå‹•çš„ã«OCRã‚’è©¦è¡Œã™ã‚‹
    """
    
    text = ""
    errors = []
    total_pages = 0
    
    # æ–¹æ³•1: pdfminer.sixã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ³ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã«æœ€å¼·ï¼‰
    try:
        from pdfminer.high_level import extract_text as pdfminer_extract
        from pdfminer.layout import LAParams
        
        logger.info("ğŸ”§ pdfminer.sixã§PDFæŠ½å‡ºã‚’è©¦è¡Œ...")
        
        # LAParamsã§ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æã‚’èª¿æ•´
        laparams = LAParams(
            line_margin=0.5,
            word_margin=0.1,
            char_margin=2.0,
            detect_vertical=True  # ç¸¦æ›¸ãã‚‚æ¤œå‡º
        )
        
        text = pdfminer_extract(str(file_path), laparams=laparams)
        
        if text and len(text.strip()) > 10:
            # ãƒ‡ãƒãƒƒã‚°: æŠ½å‡ºç›´å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèª
            sample = text[:300] if len(text) > 300 else text
            logger.info(f"ğŸ“„ pdfminer.six æŠ½å‡ºç›´å¾Œ: {repr(sample)}")
            
            # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            cleaned = clean_pdf_text(text)
            
            # â­ æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
            if is_garbled_text(cleaned):
                logger.warning("ğŸš¨ pdfminer.sixã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã«æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡º - OCRã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                # æ–‡å­—åŒ–ã‘ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€å¾Œã§OCRã‚’è©¦è¡Œ
                text = ""
            elif len(cleaned) >= 10:
                logger.info(f"âœ… pdfminer.sixã§æŠ½å‡ºæˆåŠŸ: {len(cleaned)} æ–‡å­—")
                return cleaned
        
        logger.warning("pdfminer.sixã§ã¯ååˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
    except ImportError:
        logger.warning("âš ï¸ pdfminer.sixãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        errors.append("pdfminer.six: not installed")
    except Exception as e:
        errors.append(f"pdfminer.six: {str(e)}")
        logger.warning(f"pdfminer.sixæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ–¹æ³•2: pdfplumberã‚’ä½¿ç”¨ï¼ˆpdfminer.sixã§å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    try:
        with pdfplumber.open(file_path) as pdf:
            total_pages = len(pdf.pages)
            extracted_pages = []
            
            logger.info(f"PDFã®ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}")
            
            for page_num, page in enumerate(pdf.pages, 1):
                try:
                    page_text = page.extract_text()
                    
                    # ãƒ‡ãƒãƒƒã‚°: æŠ½å‡ºç›´å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèª
                    if page_num == 1 and page_text:
                        sample = page_text[:200] if len(page_text) > 200 else page_text
                        logger.info(f"ğŸ“„ pdfplumber 1ãƒšãƒ¼ã‚¸ç›®æŠ½å‡ºç›´å¾Œ: {repr(sample)}")
                    
                    if page_text and page_text.strip():
                        # PDFãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆCIDæ–‡å­—é™¤å»ãªã©ï¼‰
                        cleaned_page_text = clean_pdf_text(page_text)
                        
                        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã«ãƒ†ã‚­ã‚¹ãƒˆãŒæ®‹ã£ã¦ã„ã‚‹ã‹ç¢ºèª
                        if cleaned_page_text and len(cleaned_page_text) > 10:
                            extracted_pages.append(f"â”â”â”â”â” ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} â”â”â”â”â”\n{cleaned_page_text}")
                            logger.info(f"ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã‚’æŠ½å‡ºæˆåŠŸ ({len(cleaned_page_text)} æ–‡å­—)")
                        else:
                            logger.warning(f"ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã¯ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã«ãƒ†ã‚­ã‚¹ãƒˆãŒæ®‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    else:
                        logger.warning(f"ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    logger.warning(f"ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã®æŠ½å‡ºã«å¤±æ•—: {e}")
                    continue
            
            if extracted_pages:
                text = "\n\n".join(extracted_pages)
                
                # â­ æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
                if is_garbled_text(text):
                    logger.warning("ğŸš¨ pdfplumberã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã«æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡º - OCRã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    text = ""  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦OCRã«é€²ã‚€
                else:
                    logger.info(f"âœ… pdfplumberã§ {len(extracted_pages)}/{total_pages} ãƒšãƒ¼ã‚¸æŠ½å‡ºæˆåŠŸ")
    except Exception as e:
        errors.append(f"pdfplumber: {str(e)}")
        logger.warning(f"pdfplumberæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ–¹æ³•2: pdfplumberã§å¤±æ•—ã—ãŸå ´åˆã€PyPDF2ã‚’è©¦ã™
    if not text.strip():
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                total_pages = len(pdf_reader.pages)
                extracted_pages = []
                
                logger.info(f"PyPDF2ã§å†è©¦è¡Œ - ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}")
                
                for page_num in range(total_pages):
                    try:
                        page = pdf_reader.pages[page_num]
                        page_text = page.extract_text()
                        
                        if page_text and page_text.strip():
                            # PDFãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                            cleaned_page_text = clean_pdf_text(page_text)
                            
                            if cleaned_page_text and len(cleaned_page_text) > 10:
                                extracted_pages.append(f"â”â”â”â”â” ãƒšãƒ¼ã‚¸ {page_num + 1}/{total_pages} â”â”â”â”â”\n{cleaned_page_text}")
                                logger.info(f"ãƒšãƒ¼ã‚¸ {page_num + 1}/{total_pages} ã‚’æŠ½å‡ºæˆåŠŸ")
                        else:
                            logger.warning(f"ãƒšãƒ¼ã‚¸ {page_num + 1}/{total_pages} ã«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
                    except Exception as e:
                        logger.warning(f"ãƒšãƒ¼ã‚¸ {page_num + 1}/{total_pages} ã®æŠ½å‡ºã«å¤±æ•—: {e}")
                        continue
                
                if extracted_pages:
                    text = "\n\n".join(extracted_pages)
                    
                    # â­ æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯
                    if is_garbled_text(text):
                        logger.warning("ğŸš¨ PyPDF2ã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã«æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡º - OCRã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                        text = ""  # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦OCRã«é€²ã‚€
                    else:
                        logger.info(f"âœ… PyPDF2ã§ {len(extracted_pages)}/{total_pages} ãƒšãƒ¼ã‚¸æŠ½å‡ºæˆåŠŸ")
        except Exception as e:
            errors.append(f"PyPDF2: {str(e)}")
            logger.warning(f"PyPDF2æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
    
    # æŠ½å‡ºã§ããŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    if text.strip():
        cleaned = clean_text(text)
        
        # â­ æ–‡å­—åŒ–ã‘ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€çµ‚ç¢ºèªï¼‰
        if is_garbled_text(cleaned):
            logger.warning("ğŸš¨ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã‚‚æ–‡å­—åŒ–ã‘ã‚’æ¤œå‡º - OCRã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            # æ–‡å­—åŒ–ã‘ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€OCRã‚’å¼·åˆ¶å®Ÿè¡Œ
            if OCR_AVAILABLE:
                try:
                    logger.info("ğŸ”„ æ–‡å­—åŒ–ã‘ãŒæ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€OCRã§å†æŠ½å‡ºã—ã¾ã™...")
                    ocr_text = extract_text_with_ocr(file_path)
                    cleaned = clean_text(ocr_text)
                    if len(cleaned) >= 10:
                        logger.info(f"ã€PDFæŠ½å‡ºå®Œäº†ï¼ˆOCRä½¿ç”¨ãƒ»æ–‡å­—åŒ–ã‘å¯¾ç­–)ã€‘æŠ½å‡ºæ–‡å­—æ•°: {len(cleaned)} æ–‡å­—")
                        return cleaned
                except Exception as ocr_error:
                    logger.error(f"âŒ OCRå‡¦ç†ã‚‚å¤±æ•—: {ocr_error}")
                    raise ValueError(f"PDFã‹ã‚‰ååˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚OCRå‡¦ç†ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {str(ocr_error)}")
            else:
                raise ValueError("PDFã«æ–‡å­—åŒ–ã‘ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸãŒã€OCRæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n\nOCRæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯: pip install pytesseract pdf2image Pillow")
        
        # æœ€çµ‚ãƒã‚§ãƒƒã‚¯: æ„å‘³ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
        if len(cleaned) < 10:
            logger.warning("âš ï¸ é€šå¸¸ã®æ–¹æ³•ã§ã¯ååˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚OCRã‚’è©¦è¡Œã—ã¾ã™...")
            # OCRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if OCR_AVAILABLE:
                try:
                    ocr_text = extract_text_with_ocr(file_path)
                    cleaned = clean_text(ocr_text)
                    if len(cleaned) >= 10:
                        # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ãƒ­ã‚°ã®ã¿ã«å‡ºåŠ›(ãƒ†ã‚­ã‚¹ãƒˆã«ã¯å«ã‚ãªã„)
                        logger.info(f"ã€PDFæŠ½å‡ºå®Œäº†ï¼ˆOCRä½¿ç”¨)ã€‘ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}ã€æŠ½å‡ºæ–‡å­—æ•°: {len(cleaned)} æ–‡å­—")
                        return cleaned
                except Exception as ocr_error:
                    logger.error(f"âŒ OCRå‡¦ç†ã‚‚å¤±æ•—: {ocr_error}")
                    raise ValueError(f"PDFã‹ã‚‰ååˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚OCRå‡¦ç†ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {str(ocr_error)}")
            else:
                raise ValueError("PDFã‹ã‚‰ååˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ç”»åƒãƒ™ãƒ¼ã‚¹ã®PDFã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nOCRæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯: pip install pytesseract pdf2image Pillow")
        
        # æŠ½å‡ºçµæœã®ã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°ã«å‡ºåŠ›(ãƒ†ã‚­ã‚¹ãƒˆã«ã¯å«ã‚ãªã„)
        logger.info(f"ã€PDFæŠ½å‡ºå®Œäº†ã€‘ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}ã€æŠ½å‡ºæ–‡å­—æ•°: {len(cleaned)} æ–‡å­—")
        return cleaned
    
    # ã™ã¹ã¦ã®æ–¹æ³•ã§å¤±æ•— â†’ OCRã‚’è©¦è¡Œ
    logger.warning("âš ï¸ é€šå¸¸ã®æ–¹æ³•ã§ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚OCRã‚’è©¦è¡Œã—ã¾ã™...")
    if OCR_AVAILABLE:
        try:
            ocr_text = extract_text_with_ocr(file_path)
            cleaned = clean_text(ocr_text)
            if len(cleaned) >= 10:
                # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ãƒ­ã‚°ã®ã¿ã«å‡ºåŠ›
                logger.info(f"ã€PDFæŠ½å‡ºå®Œäº†ï¼ˆOCRä½¿ç”¨ï¼‰ã€‘ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}ã€æŠ½å‡ºæ–‡å­—æ•°: {len(cleaned)} æ–‡å­—")
                return cleaned
        except Exception as ocr_error:
            logger.error(f"âŒ OCRå‡¦ç†ã‚‚å¤±æ•—: {ocr_error}")
    
    # OCRã‚‚å¤±æ•—ã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    error_msg = f"PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}ï¼‰ã€‚"
    if errors:
        error_msg += f"\n\nã‚¨ãƒ©ãƒ¼è©³ç´°: {'; '.join(errors)}"
    error_msg += "\n\nè€ƒãˆã‚‰ã‚Œã‚‹åŸå› :\n- ç”»åƒãƒ™ãƒ¼ã‚¹ã®PDFï¼ˆOCRå‡¦ç†ãŒå¿…è¦ï¼‰\n- æš—å·åŒ–ã•ã‚ŒãŸPDF\n- ç ´æã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«"
    
    if not OCR_AVAILABLE:
        error_msg += "\n\nğŸ’¡ OCRæ©Ÿèƒ½ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨ç”»åƒPDFã‚‚å‡¦ç†ã§ãã¾ã™:\n   pip install pytesseract pdf2image Pillow"
    
    raise ValueError(error_msg)

def clean_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–å¼·åŒ–ç‰ˆ + æ—¥æœ¬èªç©ºç™½é™¤å»ï¼‰
    """
    if not text:
        return ""
    
    # åˆ¶å¾¡æ–‡å­—ã‚’é™¤å»ï¼ˆæ”¹è¡Œã€ã‚¿ãƒ–ã€ã‚­ãƒ£ãƒªãƒƒã‚¸ãƒªã‚¿ãƒ¼ãƒ³ã¯ä¿æŒï¼‰
    text = ''.join(char for char in text if ord(char) >= 32 or char in '\n\r\t')
    
    # æ”¹è¡Œã®æ­£è¦åŒ–
    text = re.sub(r'\r\n|\r', '\n', text)
    
    # ã€è¿½åŠ ã€‘æ—¥æœ¬èªæ–‡å­—é–“ã®ä¸è¦ãªç©ºç™½ã‚’é™¤å»
    # ä¾‹: "å²© ã® ä¸­ ã§" â†’ "å²©ã®ä¸­ã§"
    # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã®é–“ã®å˜ä¸€ç©ºç™½ã‚’å‰Šé™¤
    text = re.sub(r'([\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF])\s+([\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF])', r'\1\2', text)
    
    # ä¸Šè¨˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¤‡æ•°å›é©ç”¨ï¼ˆé€£ç¶šã™ã‚‹æ–‡å­—é–“ã®ç©ºç™½ã™ã¹ã¦ã«å¯¾å¿œï¼‰
    for _ in range(5):  # æœ€å¤§5å›ç¹°ã‚Šè¿”ã—ã¦å®Œå…¨ã«é™¤å»
        text = re.sub(r'([\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF])\s+([\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF])', r'\1\2', text)
    
    # é€£ç¶šã™ã‚‹ç©ºç™½ã®å‰Šé™¤ï¼ˆè‹±èªãªã©ã®é€šå¸¸ã®ç©ºç™½ï¼‰
    text = re.sub(r' +', ' ', text)
    
    # é€£ç¶šã™ã‚‹æ”¹è¡Œã‚’æœ€å¤§2ã¤ã¾ã§ã«åˆ¶é™
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # å„è¡Œã®å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    lines = [line.strip() for line in text.split('\n')]
    text = '\n'.join(lines)
    
    # å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ãƒ»æ”¹è¡Œã‚’å‰Šé™¤
    return text.strip()


def clean_summary_result(text: str) -> str:
    """
    â­ è¦ç´„çµæœã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    AIã‹ã‚‰ã®å‡ºåŠ›ã«å«ã¾ã‚Œã‚‹ä¸è¦ãªè¨˜å·ã‚„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’é™¤å»
    
    Args:
        text: AIã‹ã‚‰ã®ç”Ÿã®è¦ç´„çµæœ
        
    Returns:
        ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if not text:
        return ""
    
    import re
    
    # å…ˆé ­ãƒ»æœ«å°¾ã®ç©ºç™½ã‚’é™¤å»
    text = text.strip()
    
    # â­ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ï¼ˆAIãŒå‡ºåŠ›ã—ã¦ã—ã¾ã£ãŸå ´åˆï¼‰
    text = re.sub(r'```[\s\S]*?```', '', text)
    text = re.sub(r'`[^`]+`', '', text)
    
    # â­ ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å‡ºåŠ›ã‚’é™¤å»
    text = re.sub(r'^[\$\#]\s+.+$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^python\s+\S+\.py.*$', '', text, flags=re.MULTILINE)
    
    # â­ importæ–‡ã‚„ã‚³ãƒ¼ãƒ‰è¡Œã‚’é™¤å»
    text = re.sub(r'^from\s+\S+\s+import.*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^import\s+\S+.*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*path\s*\(.*\).*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*urlpatterns\s*=.*$', '', text, flags=re.MULTILINE)
    
    # â­ æ—¢çŸ¥ã®æŠ€è¡“ç”¨èªãƒªã‚¹ãƒˆï¼ˆé€£çµé˜²æ­¢ï¼†æ­£è¦åŒ–ï¼‰
    known_words = [
        'Django', 'Flask', 'Python', 'JavaScript', 'TypeScript',
        'API', 'APIs', 'REST', 'GraphQL',
        'HTTP', 'HTTPS', 'HTML', 'CSS', 'JSON', 'XML', 'SQL',
        'ORM', 'WSGI', 'ASGI', 'URL', 'URI',
        'URLconf', 'URLconfs',
        'Web', 'App', 'Framework', 'Database',
        'Model', 'View', 'Template', 'Controller',
        'GET', 'POST', 'PUT', 'DELETE', 'PATCH',
        'JOIN', 'SELECT', 'INSERT', 'UPDATE',
        'Jinja', 'Werkzeug', 'Click', 'CLI',
    ]
    
    # â­ é€£ç¶šã™ã‚‹æ—¢çŸ¥ã®å˜èªã‚’åˆ†é›¢ï¼ˆè¤‡æ•°å›é©ç”¨ï¼‰
    for _ in range(3):  # 3å›ç¹°ã‚Šè¿”ã—ã¦é€£ç¶šã—ãŸå˜èªã‚’ç¢ºå®Ÿã«åˆ†é›¢
        for word in known_words:
            # å˜èªã®ç›´å¾Œã«å¤§æ–‡å­—ãŒç¶šãå ´åˆã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’æŒ¿å…¥
            pattern = f'({word})([A-Z])'
            text = re.sub(pattern, r'\1 \2', text)
            # å˜èªãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã‚‚åˆ†é›¢ï¼ˆAPIAPI â†’ API APIï¼‰
            pattern = f'({word})({word})'
            text = re.sub(pattern, r'\1 \2', text, flags=re.IGNORECASE)
    
    # â­ ä¿è­·ã™ã‚‹å˜èªï¼ˆåˆ†é›¢ã—ãªã„ï¼‰
    protected_words = ['URLconf', 'URLconfs', 'JavaScript', 'TypeScript', 'GraphQL']
    for word in protected_words:
        placeholder = f'__PROTECT_{word}__'
        text = text.replace(word, placeholder)
    
    # å°æ–‡å­—ã®å¾Œã«å¤§æ–‡å­—ãŒæ¥ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚­ãƒ£ãƒ¡ãƒ«ã‚±ãƒ¼ã‚¹ï¼‰ã‚’æ¤œå‡º
    text = re.sub(r'([a-z])([A-Z])', r'\1 \2', text)
    # å¤§æ–‡å­—ã®é€£ç¶šã®å¾Œã«å°æ–‡å­—ãŒæ¥ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆWSGIFlask â†’ WSGI Flaskï¼‰
    text = re.sub(r'([A-Z]{2,})([A-Z][a-z])', r'\1 \2', text)
    
    # ä¿è­·ã—ãŸå˜èªã‚’å¾©å…ƒ
    for word in protected_words:
        placeholder = f'__PROTECT_{word}__'
        text = text.replace(placeholder, word)
    
    # â­ æ—¥æœ¬èªã¨è‹±èªã®é–“ã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’è¿½åŠ ï¼ˆèª­ã¿ã‚„ã™ã•å‘ä¸Šï¼‰
    # è‹±èªâ†’æ—¥æœ¬èª
    text = re.sub(r'([a-zA-Z0-9])([ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥])', r'\1 \2', text)
    # æ—¥æœ¬èªâ†’è‹±èª
    text = re.sub(r'([ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥])([a-zA-Z])', r'\1 \2', text)
    
    # â­ é‡è¤‡ã—ãŸå˜èªã‚’1ã¤ã«ï¼ˆWeb Web â†’ Webï¼‰
    for word in known_words:
        pattern = f'\\b({word})\\s+\\1\\b'
        text = re.sub(pattern, r'\1', text, flags=re.IGNORECASE)
    
    # â­ ç•ªå·ä»˜ããƒªã‚¹ãƒˆã®æ”¹è¡Œã‚’ä¿®æ­£ï¼ˆ1. 2. 3. ãªã©ã®å‰ã«æ”¹è¡Œã‚’è¿½åŠ ï¼‰
    text = re.sub(r'(?<=[^\n\d])(\d{1,2}\.\s)', r'\n\1', text)
    
    # â­ ç®‡æ¡æ›¸ãè¨˜å·ã®å‰ã«ã‚‚æ”¹è¡Œã‚’è¿½åŠ 
    text = re.sub(r'(?<=[^\n])([ãƒ»â€¢\-]\s)', r'\n\1', text)
    
    # æœ«å°¾ã®ä¸è¦ãªè¨˜å·ã‚’é™¤å» (>, <, |, \, / ãªã©)
    text = re.sub(r'[><|\\\/]+\s*$', '', text)
    
    # å…ˆé ­ã®ä¸è¦ãªè¨˜å·ã‚’é™¤å» (>, <, |, \, / ãªã©)  
    text = re.sub(r'^[><|\\\/]+\s*', '', text)
    
    # ã€Œè¦ç´„:ã€ã€ŒSummary:ã€ãªã©ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
    text = re.sub(r'^(è¦ç´„|Summary|ç¿»è¨³|Translation|çµæœ|Result)\s*[:ï¼š]\s*', '', text, flags=re.IGNORECASE)
    
    # é€£ç¶šã™ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
    text = re.sub(r' +', ' ', text)
    
    # é€£ç¶šã™ã‚‹æ”¹è¡Œã‚’æœ€å¤§2ã¤ã«
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # å…ˆé ­ã®æ”¹è¡Œã‚’é™¤å»
    text = text.lstrip('\n')
    
    return text.strip()


def extract_keywords(text: str, max_keywords: int = 8) -> list:
    """
    â­ ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    ã‚·ãƒ³ãƒ—ãƒ«ãªé »åº¦ãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    
    Args:
        text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        max_keywords: æœ€å¤§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°
        
    Returns:
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    """
    import re
    from collections import Counter
    
    if not text:
        return []
    
    # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªã¨è‹±èªã®ä¸€èˆ¬çš„ãªå˜èªï¼‰
    stop_words = set([
        # æ—¥æœ¬èª
        'ã®', 'ã«', 'ã¯', 'ã‚’', 'ãŸ', 'ãŒ', 'ã§', 'ã¦', 'ã¨', 'ã—', 'ã‚Œ', 'ã•',
        'ã‚ã‚‹', 'ã„ã‚‹', 'ã‚‚', 'ã™ã‚‹', 'ã‹ã‚‰', 'ãª', 'ã“ã¨', 'ã¨ã—ã¦', 'ã„ã',
        'ã„', 'ã“ã‚Œ', 'ãã‚Œ', 'ã‚ã‚Œ', 'ã“ã®', 'ãã®', 'ãªã©', 'ã‚‚ã®', 'ãŸã‚',
        'ã‚ˆã‚Š', 'ã‚ˆã†', 'ã¾ãŸ', 'ãŠã‚ˆã³', 'ãªã‚‹', 'ã¸', 'ã‹', 'ã§ã', 'ã¨ã',
        'ã‚Œã‚‹', 'ã‚‰ã‚Œã‚‹', 'ã¾ã™', 'ã§ã™', 'ã ', 'ã§ã‚ã‚‹', 'ã¨ã„ã†', 'ãªã„',
        # è‹±èª
        'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
        'should', 'may', 'might', 'must', 'can', 'to', 'of', 'in', 'for',
        'on', 'with', 'at', 'by', 'from', 'as', 'into', 'through', 'during',
        'before', 'after', 'above', 'below', 'between', 'under', 'again',
        'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',
        'how', 'all', 'each', 'few', 'more', 'most', 'other', 'some', 'such',
        'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',
        'just', 'and', 'but', 'if', 'or', 'because', 'while', 'although',
        'it', 'its', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she',
        'we', 'they', 'what', 'which', 'who', 'whom', 'his', 'her', 'your'
    ])
    
    # æ—¥æœ¬èªã®åè©ãƒ»å›ºæœ‰åè©ã‚’æŠ½å‡ºï¼ˆã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã‚’å«ã‚€2æ–‡å­—ä»¥ä¸Šã®å˜èªï¼‰
    japanese_words = re.findall(r'[ä¸€-é¾¯ã‚¡-ãƒ´ãƒ¼]{2,}|[ã‚¡-ãƒ´ãƒ¼]{3,}', text)
    
    # è‹±å˜èªã‚’æŠ½å‡ºï¼ˆ3æ–‡å­—ä»¥ä¸Šï¼‰
    english_words = re.findall(r'[A-Za-z]{3,}', text)
    
    # å˜èªã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    word_counts = Counter()
    
    for word in japanese_words:
        word_lower = word.lower()
        if word_lower not in stop_words and len(word) >= 2:
            word_counts[word] += 1
    
    for word in english_words:
        word_lower = word.lower()
        if word_lower not in stop_words and len(word) >= 3:
            # è‹±å˜èªã¯å…ƒã®ã‚±ãƒ¼ã‚¹ã‚’ä¿æŒï¼ˆæŠ€è¡“ç”¨èªã®ãŸã‚ï¼‰
            word_counts[word] += 1
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆé »åº¦ãŒé«˜ã„ã‚‚ã®ã‚’å„ªå…ˆï¼‰
    # ãŸã ã—ã€ä¸€åº¦ã—ã‹å‡ºç¾ã—ãªã„å˜èªã¯é™¤å¤–
    keywords = [
        word for word, count in word_counts.most_common(max_keywords * 2)
        if count >= 1  # 1å›ä»¥ä¸Šå‡ºç¾
    ][:max_keywords]
    
    return keywords


def preprocess_text_for_summarization(text, max_chars=5000):
    """
    è¦ç´„ç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ï¼ˆæŠ€è¡“è¨˜äº‹å¯¾ç­–å¼·åŒ–ç‰ˆï¼‰
    - ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å…¨ä½“ã‚’é™¤å»
    - ã‚³ãƒ¼ãƒ‰ã£ã½ã„è¡Œã‚’é™¤å»
    - æ„å‘³ã®ãªã„çŸ­ã„è¡Œã‚’é™¤å»
    - é©åˆ‡ãªé•·ã•ã«åˆ¶é™
    """
    if not text:
        return text
    
    # â­ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å…¨ä½“ã‚’é™¤å»ï¼ˆ```...```ã‚„ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ï¼‰
    # Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
    text = re.sub(r'```[\s\S]*?```', '', text)
    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰
    text = re.sub(r'`[^`]+`', '', text)
    # $è¨˜å·ã§å§‹ã¾ã‚‹ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰è¡Œ
    text = re.sub(r'^\$\s+.+$', '', text, flags=re.MULTILINE)
    # >>>ã§å§‹ã¾ã‚‹Pythonãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    text = re.sub(r'^>>>.*$', '', text, flags=re.MULTILINE)
    
    lines = text.split('\n')
    cleaned_lines = []
    in_code_block = False
    indent_code_count = 0
    
    for line in lines:
        stripped = line.strip()
        
        # ç©ºè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if not stripped:
            indent_code_count = 0  # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒªã‚»ãƒƒãƒˆ
            continue
        
        # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã•ã‚ŒãŸè¡ŒãŒé€£ç¶šã™ã‚‹å ´åˆï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å¯èƒ½æ€§ï¼‰
        if line.startswith('    ') or line.startswith('\t'):
            indent_code_count += 1
            if indent_code_count >= 2:  # 2è¡Œä»¥ä¸Šã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆãŒç¶šã„ãŸã‚‰ã‚³ãƒ¼ãƒ‰ã¨ã¿ãªã™
                continue
        else:
            indent_code_count = 0
        
        # ã‚³ãƒ¼ãƒ‰ã£ã½ã„è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨˜å·ãŒå¤šã„ï¼‰
        code_chars = sum(1 for c in stripped if c in '{}[]();=<>|&$@#`')
        if len(stripped) > 10 and code_chars / len(stripped) > 0.12:
            continue
        
        # â­ ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¼·åŒ–
        code_patterns = [
            r'^(import|from)\s+[a-zA-Z]',  # Python importæ–‡
            r'^(def|class)\s+[a-zA-Z_]',  # Pythoné–¢æ•°/ã‚¯ãƒ©ã‚¹å®šç¾©
            r'^(function|const|let|var|export|async)\s+',  # JavaScriptå®šç¾©
            r'^(return|if|else|elif|for|while|try|except|with)\s*[\(\{:]',  # åˆ¶å¾¡æ§‹æ–‡
            r'^\s*(#!|//|/\*|\*/|\*\s)',  # ã‚³ãƒ¡ãƒ³ãƒˆ
            r'^[a-zA-Z_][a-zA-Z0-9_\.]*\s*[\(\[=]',  # é–¢æ•°å‘¼ã³å‡ºã—/ä»£å…¥
            r'^\s*@\w+',  # ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
            r'^[A-Z][a-z]+[A-Z]',  # ã‚­ãƒ£ãƒ¡ãƒ«ã‚±ãƒ¼ã‚¹ã®ã‚¯ãƒ©ã‚¹åï¼ˆå˜ç‹¬ï¼‰
            r'^\s*self\.',  # Pythonã®selfå‚ç…§
            r'^\s*models\.',  # Django models
            r'^.*\(.*\)\s*:?\s*$',  # é–¢æ•°å®šç¾©ã£ã½ã„è¡Œ
        ]
        is_code = False
        for pattern in code_patterns:
            if re.match(pattern, stripped):
                is_code = True
                break
        if is_code:
            continue
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å‡ºåŠ›ã£ã½ã„è¡Œ
        if stripped.startswith('$') or stripped.startswith('%') or stripped.startswith('>>>'):
            continue
        
        # çŸ­ã™ãã‚‹è¡Œï¼ˆ5æ–‡å­—ä»¥ä¸‹ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(stripped) <= 5:
            continue
        
        # æ•°å­—ã ã‘ã®è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if re.match(r'^[\d\s\.\-:]+$', stripped):
            continue
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã£ã½ã„è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if re.match(r'^[\w\-]+/[\w\-/\.]+$', stripped):
            continue
        
        cleaned_lines.append(stripped)
    
    result = '\n'.join(cleaned_lines)
    
    # é•·ã•åˆ¶é™ï¼ˆæ–‡ã®é€”ä¸­ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã«èª¿æ•´ï¼‰
    if len(result) > max_chars:
        result = result[:max_chars]
        # æœ€å¾Œã®æ–‡ã®çµ‚ã‚ã‚Šã§åˆ‡ã‚‹
        last_period = max(result.rfind('ã€‚'), result.rfind('ï¼'), result.rfind('.'))
        if last_period > max_chars * 0.7:
            result = result[:last_period + 1]
        logger.info(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™é©ç”¨: {max_chars}æ–‡å­— â†’ {len(result)}æ–‡å­—")
    
    return result


def extract_text_from_url(url):
    """
    URLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆtrafilaturaç‰ˆ - é«˜ç²¾åº¦ãªæœ¬æ–‡æŠ½å‡ºï¼‰
    
    å¯¾å¿œã‚µã‚¤ãƒˆ:
    - ä¸€èˆ¬çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆã€ãƒ–ãƒ­ã‚°
    - note.com, Qiita, Zenn ãªã©ã®æŠ€è¡“ãƒ–ãƒ­ã‚°
    - æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆDjango, Flask, Python docsç­‰ï¼‰
    - Wikipedia
    - PDFãƒ•ã‚¡ã‚¤ãƒ«
    
    éå¯¾å¿œï¼ˆæŠ€è¡“çš„åˆ¶é™ï¼‰:
    - JavaScriptå¿…é ˆã®SPAï¼ˆReact/Vueå˜ä½“ï¼‰
    - ãƒ­ã‚°ã‚¤ãƒ³å¿…é ˆã®ãƒšãƒ¼ã‚¸
    - ãƒšã‚¤ã‚¦ã‚©ãƒ¼ãƒ«ã®ã‚ã‚‹ãƒšãƒ¼ã‚¸
    """
    try:
        import trafilatura
        
        # â­ PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯ï¼ˆå…ˆã«ãƒã‚§ãƒƒã‚¯ï¼‰
        if url.lower().endswith('.pdf'):
            logger.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=Config.REQUEST_TIMEOUT)
            response.raise_for_status()
            
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(response.content)
                tmp_path = Path(tmp_file.name)
            
            try:
                text = extract_text_from_pdf(tmp_path)
                return {
                    'success': True,
                    'title': f'PDF: {url.split("/")[-1]}',
                    'content': text,
                    'url': url
                }
            finally:
                tmp_path.unlink(missing_ok=True)
        
        # â­ trafilaturaã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
        logger.info(f"ğŸ” trafilaturaã§URLå–å¾—é–‹å§‹: {url}")
        
        # HTMLã‚’å–å¾—
        downloaded = trafilatura.fetch_url(url)
        
        if not downloaded:
            logger.warning(f"âš ï¸ trafilatura: URLã®å–å¾—ã«å¤±æ•—: {url}")
            return {
                'success': False,
                'error': 'URLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒˆãŒã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚'
            }
        
        # â­ ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å¤–ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãªã—ï¼‰
        # trafilatura.extract() ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚‚å«ã‚ã¦æŠ½å‡ºã™ã‚‹
        content_text = trafilatura.extract(
            downloaded,
            include_comments=False,     # ã‚³ãƒ¡ãƒ³ãƒˆé™¤å¤–
            include_tables=False,       # ãƒ†ãƒ¼ãƒ–ãƒ«é™¤å¤–ï¼ˆã‚³ãƒ¼ãƒ‰ã£ã½ã„ã‚‚ã®ãŒå¤šã„ï¼‰
            include_images=False,       # ç”»åƒé™¤å¤–
            include_links=False,        # ãƒªãƒ³ã‚¯é™¤å¤–
            output_format='txt',        # ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            favor_precision=True,       # ç²¾åº¦å„ªå…ˆ
        )
        
        # â­ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚‚å–å¾—ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ç”¨ï¼‰
        metadata = trafilatura.extract_metadata(downloaded)
        title_text = metadata.title if metadata and metadata.title else ''
        
        if not content_text or len(content_text) < 50:
            logger.warning(f"âš ï¸ trafilatura: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒçŸ­ã™ãã¾ã™: {len(content_text) if content_text else 0}æ–‡å­—")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: BeautifulSoupã§è©¦ã™
            return extract_text_from_url_fallback(url, downloaded)
        
        # â­ æŠ½å‡ºå¾Œã®ã‚³ãƒ¼ãƒ‰é™¤å»å‡¦ç†
        content_text = remove_code_from_text(content_text)
        
        # â­ ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        content_text = content_text.replace('Â¶', '')
        content_text = re.sub(r'[\u00b6\u00a7\u2020\u2021]', '', content_text)
        content_text = re.sub(r' {2,}', ' ', content_text)
        content_text = re.sub(r'\n{3,}', '\n\n', content_text)
        content_text = '\n'.join(line.strip() for line in content_text.split('\n') if line.strip())
        
        full_text = f"{title_text}\n\n{content_text}" if title_text else content_text
        full_text = clean_text(full_text)
        
        # é•·ã•åˆ¶é™
        if len(full_text) > Config.MAX_URL_CONTENT_LENGTH:
            full_text = full_text[:Config.MAX_URL_CONTENT_LENGTH] + "..."
            logger.info(f"ğŸ“ é•·ã•åˆ¶é™é©ç”¨: {Config.MAX_URL_CONTENT_LENGTH}æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚")
        
        logger.info(f"âœ… trafilaturaå–å¾—æˆåŠŸ: {title_text[:50] if title_text else 'No title'}... ({len(full_text)}æ–‡å­—)")
        
        return {
            'success': True,
            'title': title_text,
            'content': full_text,
            'url': url
        }
        
    except ImportError:
        logger.warning("âš ï¸ trafilaturaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚BeautifulSoupã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
        return extract_text_from_url_fallback(url, None)
    except Exception as e:
        logger.error(f"âŒ URLæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {
            'success': False,
            'error': f'URLã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}'
        }


def remove_code_from_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã£ã½ã„è¡Œã‚’é™¤å»
    """
    if not text:
        return text
    
    lines = text.split('\n')
    cleaned_lines = []
    
    in_code_block = False
    
    for line in lines:
        stripped = line.strip()
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é–‹å§‹/çµ‚äº†
        if stripped.startswith('```'):
            in_code_block = not in_code_block
            continue
        
        if in_code_block:
            continue
        
        # ã‚³ãƒ¼ãƒ‰è¡Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        code_patterns = [
            r'^(import|from)\s+\w+',           # importæ–‡
            r'^(def|class|async def)\s+\w+',   # é–¢æ•°/ã‚¯ãƒ©ã‚¹å®šç¾©
            r'^(if|elif|else|for|while|try|except|finally|with)\s*[:\(]',  # åˆ¶å¾¡æ§‹æ–‡
            r'^(return|yield|raise|pass|break|continue)\s',  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            r'^\s*(self\.|cls\.)',              # self/cls
            r'^[a-z_]+\s*=\s*[\'"\[\{\(]',     # å¤‰æ•°ä»£å…¥
            r'^[A-Z][a-zA-Z]+\s*=\s*',         # å®šæ•°ä»£å…¥
            r'^@\w+',                           # ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
            r'^\s*>>>\s',                       # Python REPL
            r'^\s*\$\s',                        # ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰
            r'^\s*#\s*(coding|-\*-)',          # ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®£è¨€
            r'^\s*"""',                         # docstring
            r"^\s*'''",                         # docstring
        ]
        
        is_code = False
        for pattern in code_patterns:
            if re.match(pattern, stripped):
                is_code = True
                break
        
        # æ‹¬å¼§ã ã‚‰ã‘ã®è¡Œï¼ˆé–¢æ•°å‘¼ã³å‡ºã—ç­‰ï¼‰
        if not is_code and len(stripped) > 0:
            bracket_count = stripped.count('(') + stripped.count(')') + stripped.count('[') + stripped.count(']')
            if bracket_count > 4 and bracket_count / len(stripped) > 0.1:
                is_code = True
        
        if not is_code and stripped:
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)


def extract_text_from_url_fallback(url, html_content=None):
    """
    BeautifulSoupã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æŠ½å‡º
    """
    try:
        if html_content is None:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
            }
            session = requests.Session()
            response = session.get(url, headers=headers, timeout=Config.REQUEST_TIMEOUT)
            response.raise_for_status()
            html_content = response.text
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ä¸è¦ãªè¦ç´ ã‚’å‰Šé™¤
        for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 
                            'noscript', 'iframe', 'form', 'button', 'input',
                            'pre', 'code']):
            if element:
                element.decompose()
        
        # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        title = soup.find('title')
        title_text = title.get_text().strip() if title else ''
        
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            title_text = og_title.get('content').strip()
        
        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
        content_text = ''
        content_selectors = ['article', '[role="main"]', 'main', '.body', '.content', '#content']
        
        for selector in content_selectors:
            content = soup.select_one(selector)
            if content:
                text = content.get_text(separator=' ', strip=True)
                if len(text) > len(content_text):
                    content_text = text
                    if len(content_text) > 500:
                        break
        
        if not content_text or len(content_text) < 100:
            body = soup.find('body')
            if body:
                paragraphs = body.find_all('p')
                if paragraphs:
                    content_text = ' '.join(p.get_text(separator=' ', strip=True) for p in paragraphs if len(p.get_text(strip=True)) > 20)
        
        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        content_text = content_text.replace('Â¶', '')
        content_text = re.sub(r' {2,}', ' ', content_text)
        
        full_text = f"{title_text}\n\n{content_text}" if title_text else content_text
        full_text = clean_text(full_text)
        
        if len(full_text) < 50:
            return {
                'success': False,
                'error': f'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ååˆ†ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆ{len(full_text)}æ–‡å­—ï¼‰'
            }
        
        if len(full_text) > Config.MAX_URL_CONTENT_LENGTH:
            full_text = full_text[:Config.MAX_URL_CONTENT_LENGTH] + "..."
        
        logger.info(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å–å¾—æˆåŠŸ: {len(full_text)}æ–‡å­—")
        
        return {
            'success': True,
            'title': title_text,
            'content': full_text,
            'url': url
        }
        
    except Exception as e:
        logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {
            'success': False,
            'error': f'URLã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}'
        }


# ====== ä»¥ä¸‹ã¯å‰Šé™¤ã•ã‚ŒãŸæ—§ã‚³ãƒ¼ãƒ‰ï¼ˆBeautifulSoupç‰ˆï¼‰ã®æ®‹ã‚Šéƒ¨åˆ†ã‚’ç½®ãæ›ãˆ ======
def _legacy_pdf_extraction(url, response):
    """PDFæŠ½å‡ºã®ãƒ¬ã‚¬ã‚·ãƒ¼ã‚³ãƒ¼ãƒ‰ï¼ˆäº’æ›æ€§ã®ãŸã‚ã«æ®‹ã™ï¼‰"""
    logger.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: {url}")
    
    import tempfile
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        tmp_file.write(response.content)
        tmp_path = Path(tmp_file.name)
    
    try:
        text = extract_text_from_pdf(tmp_path)
        return {
            'success': True,
            'title': f'PDF: {url.split("/")[-1]}',
            'content': text,
        'url': url
    }
    finally:
        tmp_path.unlink(missing_ok=True)


def process_uploaded_file(file_path):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†"""
    ext = file_path.suffix.lower()
    
    try:
        if ext == '.txt':
            return file_path.read_text(encoding='utf-8')
        elif ext == '.md':
            return file_path.read_text(encoding='utf-8')
        elif ext == '.pdf':
            return extract_text_from_pdf(file_path)
        # â­ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ (PNG, JPG, JPEG, GIF, BMP, WEBP)
        elif ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']:
            return extract_text_from_image(file_path)
        else:
            return f"ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ {ext} ã¯ç¾åœ¨ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚TXTã€MDã€PDFã€ã¾ãŸã¯ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPNG, JPGç­‰ï¼‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚"
    except Exception as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"

def calculate_translation_quality(original: str, translated: str, source_lang: str, target_lang: str) -> Dict[str, float]:
    """
    â­ ç¿»è¨³å“è³ªã‚¹ã‚³ã‚¢ã‚’è©³ç´°ã«è¨ˆç®—
    
    Args:
        original: å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ
        translated: ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        source_lang: å…ƒè¨€èª
        target_lang: ç¿»è¨³å…ˆè¨€èª
        
    Returns:
        å“è³ªã‚¹ã‚³ã‚¢ã®è©³ç´° {'total': ç·åˆç‚¹, 'length': é•·ã•ç‚¹, 'completeness': å®Œå…¨æ€§ç‚¹, ...}
    """
    scores = {}
    
    # 1. é•·ã•ã®é©åˆ‡ã• (25ç‚¹)
    orig_len = len(original)
    trans_len = len(translated)
    length_ratio = trans_len / orig_len if orig_len > 0 else 0
    
    # ç¿»è¨³å…ˆè¨€èªã«ã‚ˆã‚‹ç†æƒ³çš„ãªé•·ã•æ¯”ç‡
    ideal_ratios = {
        'jpn_Jpan': (0.6, 1.2),  # æ—¥æœ¬èªã¯è‹±èªã‚ˆã‚ŠçŸ­ããªã‚ŠãŒã¡
        'eng_Latn': (0.8, 1.3),
        'default': (0.7, 1.3)
    }
    min_ratio, max_ratio = ideal_ratios.get(target_lang, ideal_ratios['default'])
    
    if min_ratio <= length_ratio <= max_ratio:
        scores['length'] = 25.0
    else:
        # ç¯„å›²å¤–ã®å ´åˆã€è·é›¢ã«å¿œã˜ã¦æ¸›ç‚¹
        distance = min(abs(length_ratio - min_ratio), abs(length_ratio - max_ratio))
        scores['length'] = max(0, 25 - distance * 50)
    
    # 2. å®Œå…¨æ€§ (25ç‚¹) - ç¿»è¨³ãŒæ¥µç«¯ã«çŸ­ã™ããªã„ã‹
    if trans_len < orig_len * 0.3:
        scores['completeness'] = 0  # å…ƒã®30%æœªæº€ã¯ä¸å®Œå…¨
    elif trans_len < orig_len * 0.5:
        scores['completeness'] = 15  # 50%æœªæº€ã¯ä¸­ç¨‹åº¦
    else:
        scores['completeness'] = 25  # 50%ä»¥ä¸Šã¯å®Œå…¨
    
    # 3. æ–‡å­—ç¨®ã®é©åˆ‡ã• (20ç‚¹)
    if target_lang == 'jpn_Jpan':
        # æ—¥æœ¬èª: ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ã®ãƒãƒ©ãƒ³ã‚¹
        hiragana = len(re.findall(r'[ã-ã‚“]', translated))
        katakana = len(re.findall(r'[ã‚¡-ãƒ´ãƒ¼]', translated))
        kanji = len(re.findall(r'[ä¸€-é¾¯]', translated))
        
        total_jp = hiragana + katakana + kanji
        if total_jp > 0:
            # ç†æƒ³çš„ãªæ¯”ç‡: ã²ã‚‰ãŒãª40-60%, ã‚«ã‚¿ã‚«ãƒŠ10-30%, æ¼¢å­—20-40%
            h_ratio = hiragana / total_jp
            k_ratio = katakana / total_jp
            j_ratio = kanji / total_jp
            
            balance_score = 0
            if 0.35 <= h_ratio <= 0.65:
                balance_score += 8
            if 0.05 <= k_ratio <= 0.35:
                balance_score += 6
            if 0.15 <= j_ratio <= 0.45:
                balance_score += 6
            
            scores['character_balance'] = balance_score
        else:
            scores['character_balance'] = 0  # æ—¥æœ¬èªæ–‡å­—ãŒãªã„
    else:
        # è‹±èªãªã©: åŸºæœ¬çš„ã«æº€ç‚¹
        scores['character_balance'] = 20
    
    # 4. å¥èª­ç‚¹ã®é©åˆ‡ã• (15ç‚¹)
    if target_lang == 'jpn_Jpan':
        # æ—¥æœ¬èªå¥èª­ç‚¹(ã€ã€‚)ã®æ•°
        jp_punctuation = len(re.findall(r'[ã€ã€‚]', translated))
        # è‹±èªå¥èª­ç‚¹(, .)ãŒæ®‹ã£ã¦ã„ãªã„ã‹
        en_punctuation = len(re.findall(r'[,.]', translated))
        
        if jp_punctuation > 0 and en_punctuation == 0:
            scores['punctuation'] = 15
        elif jp_punctuation > 0:
            scores['punctuation'] = 10  # è‹±èªå¥èª­ç‚¹ãŒæ··åœ¨
        else:
            scores['punctuation'] = 5  # å¥èª­ç‚¹ãªã—
    else:
        scores['punctuation'] = 15
    
    # 5. ç¹°ã‚Šè¿”ã—ã®å°‘ãªã• (15ç‚¹)
    # åŒã˜å˜èªãŒ3å›ä»¥ä¸Šé€£ç¶šã—ã¦ã„ãªã„ã‹
    repetitions = len(re.findall(r'(\w+)\1{2,}', translated))
    if repetitions == 0:
        scores['no_repetition'] = 15
    elif repetitions <= 2:
        scores['no_repetition'] = 10
    else:
        scores['no_repetition'] = max(0, 15 - repetitions * 3)
    
    # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
    scores['total'] = sum(scores.values())
    
    logger.info(f"â­ å“è³ªè©³ç´°: ç·åˆ{scores['total']:.1f}% "
                f"(é•·ã•{scores['length']:.0f} å®Œå…¨æ€§{scores['completeness']:.0f} "
                f"æ–‡å­—ç¨®{scores['character_balance']:.0f} å¥èª­ç‚¹{scores['punctuation']:.0f} "
                f"ç¹°è¿”{scores['no_repetition']:.0f})")
    
    return scores

# Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = Flask(__name__)
app.config.from_object(Config)

# SocketIOåˆæœŸåŒ– (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—é€šçŸ¥ç”¨)
socketio = SocketIO(app, cors_allowed_origins="*")

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
Config.UPLOAD_FOLDER.mkdir(exist_ok=True)

# Hugging Face AIã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
hf_service = get_hf_service()

logger.info(f"Hugging Face Service initialized. Available: {hf_service.available}")

# â­ Kaggle AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆApertus-8Bå°‚ç”¨ï¼‰
kaggle_client = None
if os.getenv('USE_KAGGLE_API', '').lower() == 'true':
    try:
        kaggle_api_url = os.getenv('KAGGLE_API_URL')
        kaggle_api_key = os.getenv('KAGGLE_API_KEY')
        kaggle_timeout = int(os.getenv('KAGGLE_API_TIMEOUT', '60'))
        
        if kaggle_api_url:
            kaggle_client = KaggleAIClient(
                base_url=kaggle_api_url,
                api_key=kaggle_api_key,
                timeout=kaggle_timeout
            )
            if kaggle_client.is_available():
                logger.info(f"ğŸš€ Kaggle Apertus-8B åˆæœŸåŒ–å®Œäº†. URL: {kaggle_api_url}")
            else:
                logger.warning(f"âš ï¸ Kaggle APIã¯è¨­å®šã•ã‚Œã¦ã„ã¾ã™ãŒã€ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“")
                logger.warning(f"   Kaggle NotebookãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        else:
            logger.error("âŒ KAGGLE_API_URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        logger.error(f"âŒ Kaggle AI ClientåˆæœŸåŒ–å¤±æ•—: {e}")
        kaggle_client = None
else:
    logger.error("âŒ USE_KAGGLE_API=true ã«è¨­å®šã—ã¦ãã ã•ã„ (.envãƒ•ã‚¡ã‚¤ãƒ«)")

if not kaggle_client or not kaggle_client.is_available():
    logger.error("=" * 60)
    logger.error("âš ï¸ Kaggle Apertus-8BãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    logger.error("   ã“ã®ã‚¢ãƒ—ãƒªã¯Kaggleå°‚ç”¨ã§ã™ã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
    logger.error("   1. .envãƒ•ã‚¡ã‚¤ãƒ«ã§USE_KAGGLE_API=trueã«è¨­å®š")
    logger.error("   2. KAGGLE_API_URLã¨KAGGLE_API_KEYã‚’è¨­å®š")
    logger.error("   3. Kaggle NotebookãŒèµ·å‹•ä¸­ã§ã‚ã‚‹ã“ã¨")
    logger.error("=" * 60)

# â­ ãƒ­ã‚°ã‚¤ãƒ³å¿…é ˆãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
def login_required(f):
    """ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç”¨ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            return jsonify({'success': False, 'error': 'ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™'}), 401
        return f(*args, **kwargs)
    return decorated_function

def hash_password(password):
    """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–"""
    return hashlib.sha256(password.encode()).hexdigest()

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return render_template('index.html')

@app.route('/history')
def history():
    """å±¥æ­´ãƒšãƒ¼ã‚¸"""
    return render_template('history.html')

@app.route('/about')
def about():
    """ã‚¢ãƒã‚¦ãƒˆãƒšãƒ¼ã‚¸"""
    return render_template('about.html')

@app.route('/learning-dashboard')
def learning_dashboard():
    """Apertuså­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - AIã‚¼ãƒŸç”¨"""
    return render_template('learning_dashboard.html')

@app.route('/api/upload-pdf', methods=['POST'])
def api_upload_pdf():
    """PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å°‚ç”¨API - pdfminer.sixã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒé€ä¿¡ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé€ä¿¡ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        file = request.files['file']
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã§ãªã„ã‹ç¢ºèª
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ç¢ºèª
        if not file.filename.lower().endswith('.pdf'):
            return jsonify({
                'success': False,
                'error': 'PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™'
            }), 400
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            file.save(tmp_file.name)
            tmp_path = Path(tmp_file.name)
        
        try:
            # extract_text_from_pdf()ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            logger.info(f"ğŸ“„ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ¼ãƒãƒ¼å´ã§å‡¦ç†: {file.filename}")
            extracted_text = extract_text_from_pdf(tmp_path)
            
            return jsonify({
                'success': True,
                'text': extracted_text,
                'filename': file.filename
            })
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if tmp_path.exists():
                tmp_path.unlink()
    
    except Exception as e:
        logger.error(f"âŒ PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'PDFã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500


@app.route('/api/upload-image', methods=['POST'])
def api_upload_image():
    """â­ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰API - OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆèª¬æ˜æ›¸ã®å†™çœŸå¯¾å¿œï¼‰"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒé€ä¿¡ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé€ä¿¡ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        file = request.files['file']
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã§ãªã„ã‹ç¢ºèª
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ç¢ºèª
        allowed_image_ext = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in allowed_image_ext:
            return jsonify({
                'success': False,
                'error': f'å¯¾å¿œã—ã¦ã„ã‚‹ç”»åƒå½¢å¼: {", ".join(allowed_image_ext)}'
            }), 400
        
        # OCRæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
        if not OCR_AVAILABLE:
            return jsonify({
                'success': False,
                'error': 'OCRæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚µãƒ¼ãƒãƒ¼ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚'
            }), 503
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
            file.save(tmp_file.name)
            tmp_path = Path(tmp_file.name)
        
        try:
            # ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            logger.info(f"ğŸ–¼ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’OCRå‡¦ç†: {file.filename}")
            extracted_text = extract_text_from_image(tmp_path)
            
            return jsonify({
                'success': True,
                'text': extracted_text,
                'filename': file.filename,
                'message': 'ğŸ“· ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã—ãŸ'
            })
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if tmp_path.exists():
                tmp_path.unlink()
    
    except Exception as e:
        logger.error(f"âŒ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'ç”»åƒã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500


@app.route('/api/summarize', methods=['POST'])

def api_summarize():
    """è¦ç´„API - å¤šè¨€èªç¿»è¨³å¯¾å¿œç‰ˆ + å‹•çš„èª¿æ•´ + å±¥æ­´ä¿å­˜ + ã‚¹ã‚¿ã‚¤ãƒ«é¸æŠ + Apertus LLMå¯¾å¿œ + ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—"""
    try:
        # â­ ã‚¿ã‚¹ã‚¯IDç”Ÿæˆï¼ˆé€²æ—è¿½è·¡ç”¨ï¼‰
        task_id = str(uuid.uuid4())
        
        data = request.get_json() if request.is_json else request.form
        text = data.get('text', '').strip()
        max_length = int(data.get('max_length', 200))
        min_length = int(data.get('min_length', 50))
        summary_mode = data.get('summary_mode', 'short')  # 'short' or 'long'
        source_lang = data.get('source_lang', 'auto')  # å…¥åŠ›è¨€èª
        target_lang = data.get('target_lang', 'jpn_Jpan')  # å‡ºåŠ›è¨€èª
        style = data.get('style', 'balanced')  # â­ è¦ç´„ã‚¹ã‚¿ã‚¤ãƒ«
        model_type = 'kaggle'  # â­ Kaggle Apertus-8Bå›ºå®š
        
        # â­ åˆæœŸé€²æ—é€ä¿¡
        send_progress(task_id, 'validate', 5, 'ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œè¨¼ä¸­...')
        
        if not text:
            return jsonify({
                'success': False,
                'error': 'ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        # â­ PDFç­‰ã®é•·æ–‡å¯¾å¿œ: åˆ¶é™ã‚’30,000æ–‡å­—ã«ç·©å’Œ
        max_allowed_length = 30000
        if len(text) > max_allowed_length:
            return jsonify({
                'success': False,
                'error': f'ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆæœ€å¤§{max_allowed_length:,}æ–‡å­—ï¼‰ã€‚ç¾åœ¨: {len(text):,}æ–‡å­—'
            }), 400
        
        # ğŸ”¥ è¦ç´„ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸå›ºå®šæ–‡å­—æ•°
        text_length = len(text)
        if summary_mode == 'long':
            # è©³ç´°è¦ç´„: 800-1000æ–‡å­—
            max_length = 1000
            min_length = 800
        else:
            # é€šå¸¸è¦ç´„: 200-400æ–‡å­—
            max_length = 400
            min_length = 200
        
        logger.info(f"ğŸ“ å‹•çš„èª¿æ•´: å…¥åŠ›{text_length}æ–‡å­— â†’ è¦ç´„{min_length}-{max_length}æ–‡å­—")
        logger.info(f"ğŸ¨ ã‚¹ã‚¿ã‚¤ãƒ«: {style}")
        logger.info(f"ğŸš€ ãƒ¢ãƒ‡ãƒ«: Kaggle Apertus-8B (å›ºå®š)")
        
        # â­ é€²æ—é€ä¿¡: æº–å‚™å®Œäº†
        send_progress(task_id, 'prepare', 15, 'è¦ç´„å‡¦ç†ã®æº–å‚™ä¸­...')
        
        # Kaggle Apertus-8Bã§è¦ç´„ãƒ»ç¿»è¨³å®Ÿè¡Œ
        start_time = time.time()
        
        if not kaggle_client:
            logger.error("âŒ Kaggle APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return jsonify({
                'success': False,
                'error': 'âš ï¸ ã‚µãƒ¼ãƒãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: KAGGLE_API_URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚',
                'task_id': task_id
            }), 500
        
        if not kaggle_client.is_available():
            logger.error("âŒ Kaggle APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return jsonify({
                'success': False,
                'error': 'ğŸ”Œ AI ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚\n\nè€ƒãˆã‚‰ã‚Œã‚‹åŸå› :\nâ€¢ Kaggle NotebookãŒåœæ­¢ã—ã¦ã„ã‚‹\nâ€¢ ngrok URLãŒå¤‰æ›´ã•ã‚ŒãŸ\nâ€¢ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®å•é¡Œ\n\nã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚',
                'task_id': task_id
            }), 503
        
        # ğŸš€ Kaggle Apertus-8Bã§è¦ç´„å®Ÿè¡Œ
        logger.info("ğŸš€ Kaggle Apertus-8B ã§è¦ç´„å®Ÿè¡Œ...")
        logger.info(f"ğŸ“ è¨­å®š: å…¥åŠ›è¨€èª={source_lang}, å‡ºåŠ›è¨€èª={target_lang}, ãƒ¢ãƒ¼ãƒ‰={summary_mode}, ã‚¹ã‚¿ã‚¤ãƒ«={style}")
        
        # â­ é€²æ—é€ä¿¡: è¦ç´„ä¸­
        send_progress(task_id, 'summarize', 30, 'AI ãŒè¦ç´„ã‚’ç”Ÿæˆä¸­... (ã“ã‚Œã«ã¯æ•°ç§’ã‹ã‹ã‚Šã¾ã™)')
        
        # â­ è¨€èªã‚³ãƒ¼ãƒ‰ã‚’äººé–“å¯èª­ãªè¨€èªåã«å¤‰æ› (config.pyã‹ã‚‰å…±é€šå®šç¾©ã‚’ä½¿ç”¨)
        from config import get_language_name
        source_lang_name = get_language_name(source_lang)
        target_lang_name = get_language_name(target_lang, 'Japanese')
        
        # â­ æ–°ã—ã„/summarizeã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼ˆApertusã®å¤šè¨€èªè¦ç´„æ©Ÿèƒ½ï¼‰
        kaggle_result = kaggle_client.summarize(
            text=text,
            max_length=max_length,
            source_lang=source_lang_name,
            target_lang=target_lang_name,
            style=style,
            summary_mode=summary_mode
        )
        
        # â­ é€²æ—é€ä¿¡: è¦ç´„å®Œäº†ã€å¾Œå‡¦ç†ä¸­
        send_progress(task_id, 'process', 70, 'è¦ç´„çµæœã‚’æ•´å½¢ä¸­...')
        
        if not kaggle_result or not kaggle_result.get('success'):
            error_msg = kaggle_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼') if kaggle_result else 'å¿œç­”ãªã—'
            logger.error(f"âŒ Kaggleè¦ç´„å¤±æ•—: {error_msg}")
            
            # â­ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›
            if 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ' in error_msg or 'Timeout' in error_msg:
                user_error = 'â±ï¸ å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¾ã—ãŸã€‚\n\nãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã§å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚'
            elif 'HTTP 5' in error_msg:
                user_error = 'ğŸ”§ AIã‚µãƒ¼ãƒãƒ¼ã§å†…éƒ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\nã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚'
            elif 'HTTP 4' in error_msg:
                user_error = 'ğŸ” èªè¨¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\nç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚'
            else:
                user_error = f'âŒ è¦ç´„å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\nè©³ç´°: {error_msg}'
            
            return jsonify({
                'success': False,
                'error': user_error
            }), 500
        
        # /summarizeã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯'summary'ã‚­ãƒ¼ã§çµæœã‚’è¿”ã™
        summary_text = kaggle_result.get('summary', '')
        
        # â­ è¦ç´„çµæœã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆä¸è¦ãªè¨˜å·ã‚’é™¤å»ï¼‰
        summary_text = clean_summary_result(summary_text)
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼‰
        logger.info(f"ğŸ” è¦ç´„çµæœï¼ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼‰: {summary_text[:200]}...")
        
        response = type('obj', (object,), {
            'success': True,
            'result': summary_text,
            'model_used': 'Kaggle Apertus-8B (1,811è¨€èªå¯¾å¿œ)',
            'token_usage': None,
            'error': None
        })()
        
        execution_time = time.time() - start_time
        
        # â­ é€²æ—é€ä¿¡: å“è³ªè©•ä¾¡ä¸­
        send_progress(task_id, 'evaluate', 85, 'å“è³ªã‚’è©•ä¾¡ä¸­...')
        
        # â­ å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆè©³ç´°ç‰ˆï¼‰
        quality_score = 0.0
        quality_details = {}
        if response.success and response.result:
            quality_details = calculate_translation_quality(text, response.result, source_lang, target_lang)
            quality_score = quality_details.get('total', 0)
        
        # â­ é€²æ—é€ä¿¡: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ä¸­
        send_progress(task_id, 'save', 95, 'å±¥æ­´ã‚’ä¿å­˜ä¸­...')
        
        # å‡¦ç†çµæœã‚’ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¨˜éŒ²
        processing_result = ProcessingResult(
            id=str(uuid.uuid4()),
            timestamp=datetime.now(),
            type=ProcessingType.SUMMARIZE,
            status=ProcessingStatus.COMPLETED if response.success else ProcessingStatus.FAILED,
            original_text=text[:200] + "..." if len(text) > 200 else text,
            result=response.result,
            execution_time=execution_time,
            model_used=response.model_used,
            confidence=quality_score / 100.0,
            token_usage=response.token_usage or {},
            original_length=len(text),
            result_length=len(response.result),
            compression_ratio=len(response.result) / len(text) if text else 0.0,
            error=response.error if not response.success else None
        )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ã¯ä¿å­˜ã—ãªã„ï¼ˆCookieã‚µã‚¤ã‚ºåˆ¶é™å¯¾ç­–ï¼‰
        # ä»£ã‚ã‚Šã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã™ã‚‹
        
        # ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å±¥æ­´ä¿å­˜ï¼ˆâ­ æ–‡å­—æ•°åˆ¶é™ã‚’å¢—åŠ  + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¿½åŠ ï¼‰
        try:
            db = get_db()
            token_count = response.token_usage.get('total_tokens', 0) if response.token_usage else 0
            
            # â­ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            keywords = extract_keywords(text, max_keywords=8)
            keywords_json = json.dumps(keywords, ensure_ascii=False) if keywords else None
            
            db.save_translation(
                source_lang=source_lang,
                target_lang=target_lang,
                original_text=text[:5000],  # â­ æœ€åˆã®5000æ–‡å­—ã¾ã§ä¿å­˜ï¼ˆå¢—åŠ ï¼‰
                translated_text=response.result[:3000] if response.success else "",  # â­ æœ€å¤§3000æ–‡å­—
                summary_mode=summary_mode,
                quality_score=quality_score,
                file_name=None,
                processing_time=execution_time,
                token_count=token_count,
                keywords=keywords_json  # â­ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¿å­˜
            )
            logger.info("ğŸ’¾ ç¿»è¨³å±¥æ­´ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as db_error:
            logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {db_error}")
        
        # â­ é€²æ—é€ä¿¡: å®Œäº†
        send_progress(task_id, 'complete', 100, 'å®Œäº†ï¼')
        
        if response.success:
            return jsonify({
                'success': True,
                'summary': response.result,
                'original_length': len(text),
                'summary_length': len(response.result),
                'compression_ratio': len(response.result) / len(text) if text else 0.0,
                'execution_time': execution_time,
                'model_used': response.model_used,
                'confidence': quality_score / 100.0,
                'quality_score': round(quality_score, 1),
                'quality_details': {
                    'length': round(quality_details.get('length', 0), 1),
                    'completeness': round(quality_details.get('completeness', 0), 1),
                    'character_balance': round(quality_details.get('character_balance', 0), 1),
                    'punctuation': round(quality_details.get('punctuation', 0), 1),
                    'no_repetition': round(quality_details.get('no_repetition', 0), 1)
                },
                'token_usage': response.token_usage or {},
                'task_id': task_id
                # quality_metricså±æ€§ã¯å­˜åœ¨ã—ãªã„ãŸã‚å‰Šé™¤
            })
        else:
            return jsonify({
                'success': False,
                'error': response.error or 'è¦ç´„å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'
            }), 500
        
    except Exception as e:
        logger.error(f"è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'è¦ç´„å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500

@app.route('/api/expand', methods=['POST'])
def api_expand():
    """æ–‡ç« å±•é–‹API - Kaggle Apertus-8Bçµ±åˆç‰ˆ"""
    try:
        data = request.get_json() if request.is_json else request.form
        text = data.get('text', '').strip()
        target_length = int(data.get('target_length', 300))
        target_lang_code = data.get('target_lang', 'jpn_Jpan')
        
        if not text:
            return jsonify({
                'success': False,
                'error': 'ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        if len(text) > 300:
            return jsonify({
                'success': False,
                'error': 'å±•é–‹å…ƒãƒ†ã‚­ã‚¹ãƒˆã¯300æ–‡å­—ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„'
            }), 400
        
        # â­ Kaggle APIã§å±•é–‹
        start_time = time.time()
        
        if not kaggle_client:
            return jsonify({
                'success': False,
                'error': 'Kaggle APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
            }), 503
        
        if not kaggle_client.is_available():
            return jsonify({
                'success': False,
                'error': 'ğŸ”Œ AIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚Kaggle NotebookãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
            }), 503
        
        # â­ è¨€èªã‚³ãƒ¼ãƒ‰ã‚’è¨€èªåã«å¤‰æ›
        from config import get_language_name
        target_lang = get_language_name(target_lang_code, 'Japanese')
        
        # Kaggle /expand ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—
        kaggle_result = kaggle_client.expand(
            text=text,
            target_length=target_length,
            target_lang=target_lang
        )
        
        execution_time = time.time() - start_time
        
        if kaggle_result and kaggle_result.get('success'):
            expanded_text = kaggle_result.get('result', '')
            
            # â­ å±•é–‹çµæœã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆä¸è¦ãªè¨˜å·ã‚’é™¤å»ï¼‰
            expanded_text = clean_summary_result(expanded_text)
            
            # â­ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å±•é–‹å±¥æ­´ã‚’ä¿å­˜
            try:
                db = get_db()
                
                # â­ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆå±•é–‹å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ï¼‰
                keywords = extract_keywords(expanded_text, max_keywords=8)
                keywords_json = json.dumps(keywords, ensure_ascii=False) if keywords else None
                
                db.save_translation(
                    source_lang='auto',
                    target_lang=target_lang_code,
                    original_text=text[:5000],
                    translated_text=expanded_text[:3000],
                    summary_mode='expand',  # â­ å±•é–‹ã¨ã—ã¦è¨˜éŒ²
                    quality_score=90.0,
                    file_name=None,
                    processing_time=execution_time,
                    token_count=0,
                    keywords=keywords_json  # â­ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä¿å­˜
                )
                logger.info("ğŸ’¾ å±•é–‹å±¥æ­´ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸ")
            except Exception as db_error:
                logger.warning(f"âš ï¸ å±•é–‹å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {db_error}")
            
            return jsonify({
                'success': True,
                'expanded_text': expanded_text,
                'original_length': len(text),
                'expanded_length': len(expanded_text),
                'expansion_ratio': len(expanded_text) / len(text) if text else 0.0,
                'execution_time': execution_time,
                'model_used': 'Apertus-8B-Instruct',
                'confidence': 0.9
            })
        else:
            error_msg = kaggle_result.get('error', 'å±•é–‹å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ') if kaggle_result else 'å±•é–‹å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ'
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
        
    except Exception as e:
        logger.error(f"å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'æ–‡ç« å±•é–‹ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500


@app.route('/api/explain-code', methods=['POST'])
def api_explain_code():
    """ã‚³ãƒ¼ãƒ‰è§£èª¬API - Kaggle Apertus-8Bçµ±åˆç‰ˆ"""
    try:
        data = request.get_json() if request.is_json else request.form
        code = data.get('code', '').strip()
        language = data.get('language', 'auto')  # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª
        target_lang_code = data.get('target_lang', 'jpn_Jpan')  # è§£èª¬ã®å‡ºåŠ›è¨€èª
        
        if not code:
            return jsonify({
                'success': False,
                'error': 'ã‚³ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        if len(code) > 5000:
            return jsonify({
                'success': False,
                'error': 'ã‚³ãƒ¼ãƒ‰ã¯5000æ–‡å­—ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„'
            }), 400
        
        # â­ Kaggle APIã§è§£èª¬
        start_time = time.time()
        
        if not kaggle_client:
            return jsonify({
                'success': False,
                'error': 'Kaggle APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
            }), 503
        
        if not kaggle_client.is_available():
            return jsonify({
                'success': False,
                'error': 'ğŸ”Œ AIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚Kaggle NotebookãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
            }), 503
        
        # â­ è¨€èªã‚³ãƒ¼ãƒ‰ã‚’è¨€èªåã«å¤‰æ›
        from config import get_language_name
        target_lang = get_language_name(target_lang_code, 'Japanese')
        
        # Kaggle /explain-code ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—
        kaggle_result = kaggle_client.explain_code(
            code=code,
            language=language,
            target_lang=target_lang
        )
        
        execution_time = time.time() - start_time
        
        if kaggle_result and kaggle_result.get('success'):
            explanation = kaggle_result.get('explanation', '')
            detected_lang = kaggle_result.get('detected_language', language)
            
            # â­ çµæœã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            explanation = clean_summary_result(explanation)
            
            return jsonify({
                'success': True,
                'explanation': explanation,
                'code_length': len(code),
                'explanation_length': len(explanation),
                'detected_language': detected_lang,
                'execution_time': execution_time,
                'model_used': 'Apertus-8B-Instruct'
            })
        else:
            error_msg = kaggle_result.get('error', 'ã‚³ãƒ¼ãƒ‰è§£èª¬ã«å¤±æ•—ã—ã¾ã—ãŸ') if kaggle_result else 'ã‚³ãƒ¼ãƒ‰è§£èª¬ã«å¤±æ•—ã—ã¾ã—ãŸ'
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
        
    except Exception as e:
        logger.error(f"ã‚³ãƒ¼ãƒ‰è§£èª¬ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'ã‚³ãƒ¼ãƒ‰è§£èª¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500


@app.route('/api/url-summarize', methods=['POST'])
def api_url_summarize():
    """URLè¦ç´„API - Kaggle Apertus-8Bçµ±åˆç‰ˆ"""
    try:
        data = request.get_json() if request.is_json else request.form
        url = data.get('url', '').strip()
        max_length = int(data.get('max_length', 200))
        summary_mode = data.get('summary_mode', 'short')  # 'short' or 'long'
        target_lang = data.get('target_lang', 'Japanese')
        style = data.get('style', 'balanced')
        
        # â­ æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œå‡ºã—ã¦è§£èª¬ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›´
        tech_doc_patterns = [
            'docs.', 'documentation', '/docs/', '/doc/',
            'readthedocs', 'palletsprojects', 'djangoproject',
            'reactjs.org', 'react.dev', 'vuejs.org', 'angular.io',
            'numpy.org', 'pandas.pydata', 'pytorch.org', 'tensorflow.org',
            'developer.mozilla', 'devdocs.io',
            '/api/', '/reference/', '/guide/', '/tutorial/',
            'github.com', 'gitlab.com',
        ]
        is_tech_doc = any(pattern in url.lower() for pattern in tech_doc_patterns)
        
        if is_tech_doc:
            style = 'tech_doc'
            logger.info(f"ğŸ“š æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œå‡º: {url[:50]}... â†’ tech_docã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨")
        
        if not url:
            return jsonify({
                'success': False,
                'error': 'URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        # URLå½¢å¼ãƒã‚§ãƒƒã‚¯
        parsed = urlparse(url)
        if not parsed.scheme or not parsed.netloc:
            return jsonify({
                'success': False,
                'error': 'æœ‰åŠ¹ãªURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„'
            }), 400
        
        # URLè¨˜äº‹å–å¾—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œï¼‰
        extract_result = extract_text_from_url(url)
        if not extract_result['success']:
            return jsonify(extract_result), 400
        
        # â­ ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†ï¼ˆã‚³ãƒ¼ãƒ‰ã‚„ä¸è¦ãªè¡Œã‚’é™¤å»ã€é•·ã•åˆ¶é™ï¼‰
        original_length = len(extract_result['content'])
        processed_text = preprocess_text_for_summarization(extract_result['content'], max_chars=5000)
        logger.info(f"ğŸ“ å‰å‡¦ç†: {original_length}æ–‡å­— â†’ {len(processed_text)}æ–‡å­—")
        
        if len(processed_text) < 50:
            return jsonify({
                'success': False,
                'error': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ååˆ†ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®ã‚µã‚¤ãƒˆã¯ã‚³ãƒ¼ãƒ‰ãŒä¸­å¿ƒã®æŠ€è¡“è¨˜äº‹ã€ã¾ãŸã¯JavaScriptã§å‹•çš„ã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚'
            }), 400
        
        # â­ Kaggle APIã§è¦ç´„
        start_time = time.time()
        
        if not kaggle_client:
            return jsonify({
                'success': False,
                'error': 'Kaggle APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
            }), 503
        
        if not kaggle_client.is_available():
            return jsonify({
                'success': False,
                'error': 'ğŸ”Œ AIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚Kaggle NotebookãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
            }), 503
        
        # â­ è¨€èªã‚³ãƒ¼ãƒ‰ã‚’äººé–“å¯èª­ãªè¨€èªåã«å¤‰æ› (config.pyã‹ã‚‰å…±é€šå®šç¾©ã‚’ä½¿ç”¨)
        from config import get_language_name
        target_lang_name = get_language_name(target_lang, 'Japanese')
        logger.info(f"ğŸ“ URLè¦ç´„: å‡ºåŠ›è¨€èª={target_lang} â†’ {target_lang_name}")
        
        # Kaggle /summarize ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã—
        kaggle_result = kaggle_client.summarize(
            text=processed_text,  # â­ å‰å‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
            max_length=max_length,
            source_lang='auto-detect',
            target_lang=target_lang_name,  # â­ å¤‰æ›å¾Œã®è¨€èªåã‚’ä½¿ç”¨
            style=style,
            summary_mode=summary_mode
        )
        
        execution_time = time.time() - start_time
        
        if kaggle_result and kaggle_result.get('success'):
            summary = kaggle_result.get('summary', '')
            
            # â­ è¦ç´„çµæœã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆä¸è¦ãªè¨˜å·ã‚’é™¤å»ï¼‰
            summary = clean_summary_result(summary)
            
            return jsonify({
                'success': True,
                'title': extract_result['title'],
                'url': url,
                'summary': summary,
                'original_length': len(extract_result['content']),
                'summary_length': len(summary),
                'compression_ratio': len(summary) / len(extract_result['content']) if extract_result['content'] else 0.0,
                'execution_time': execution_time,
                'model_used': 'Apertus-8B-Instruct',
                'confidence': 0.9
            })
        else:
            error_msg = kaggle_result.get('error', 'URLè¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ') if kaggle_result else 'URLè¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ'
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
        
    except Exception as e:
        logger.error(f"URLè¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'URLè¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500

@app.route('/api/upload', methods=['POST'])
def api_upload():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰API"""
    try:
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        if not allowed_file(file.filename):
            return jsonify({
                'success': False,
                'error': 'ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™'
            }), 400
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        filename = secure_filename(file.filename)
        file_path = Config.UPLOAD_FOLDER / filename
        file.save(file_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        text = process_uploaded_file(file_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        file_path.unlink(missing_ok=True)
        
        return jsonify({
            'success': True,
            'text': text,
            'filename': filename
        })
        
    except Exception as e:
        logger.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500

@app.route('/api/history')
def api_history():
    """å±¥æ­´APIï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»å“è³ªã‚¹ã‚³ã‚¢å¯¾å¿œ"""
    try:
        db = get_db()
        # â­ æœ€æ–°200ä»¶ã‚’å–å¾—ï¼ˆç›´æ¥SQLæ¥ç¶šã‚’ä½¿ç”¨ï¼‰
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            history_rows = cursor.execute('''
                SELECT id, timestamp as created_at, source_lang, target_lang, 
                       original_text, translated_text as result_text, 
                       summary_mode as operation_type, processing_time as execution_time,
                       quality_score, keywords
                FROM translation_history
                ORDER BY timestamp DESC
                LIMIT 200
            ''').fetchall()
        
        # è¾æ›¸å½¢å¼ã«å¤‰æ›
        history = []
        for row in history_rows:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
            keywords = []
            if row['keywords']:
                try:
                    keywords = json.loads(row['keywords'])
                except:
                    keywords = []
            
            history.append({
                'id': row['id'],
                'operation_type': row['operation_type'] or 'summarize',
                'original_text': row['original_text'],
                'result_text': row['result_text'],
                'source_lang': row['source_lang'],
                'target_lang': row['target_lang'],
                'execution_time': row['execution_time'],
                'created_at': row['created_at'],
                'quality_score': row['quality_score'],  # â­ å“è³ªã‚¹ã‚³ã‚¢è¿½åŠ 
                'keywords': keywords  # â­ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¿½åŠ 
            })
        
        return jsonify({
            'success': True,
            'history': history,
            'total': len(history)
        })
    except Exception as e:
        logger.error(f"å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'history': [],
            'total': 0
        })

@app.route('/api/stats')
def api_stats():
    """çµ±è¨ˆAPIï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰"""
    try:
        db = get_db()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆç›´æ¥SQLæ¥ç¶šã‚’ä½¿ç”¨ï¼‰
        with sqlite3.connect(db.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            stats_query = cursor.execute('''
                SELECT 
                    COUNT(*) as total_operations,
                    AVG(processing_time) as avg_execution_time,
                    SUM(LENGTH(original_text)) as total_chars_processed
                FROM translation_history
            ''').fetchone()
        
        if not stats_query or stats_query['total_operations'] == 0:
            return jsonify({
                'total_operations': 0,
                'average_execution_time': 0,
                'total_text_processed': 0
            })
        
        return jsonify({
            'total_operations': stats_query['total_operations'],
            'average_execution_time': stats_query['avg_execution_time'] or 0,
            'total_text_processed': stats_query['total_chars_processed'] or 0
        })
    except Exception as e:
        logger.error(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'total_operations': 0,
            'average_execution_time': 0,
            'total_text_processed': 0
        })

# ğŸ“ Apertuså­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯API

@app.route('/api/feedback', methods=['POST'])
def api_feedback():
    """
    ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†API - AIã‚¼ãƒŸç”¨ï¼ˆUTF-8å¯¾å¿œå¼·åŒ–ç‰ˆï¼‰
    Apertuså­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¨é€£æº
    """
    try:
        from services.apertus_learning_system import get_learning_system
        
        # UTF-8ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’æ˜ç¤ºçš„ã«å®Ÿè¡Œ
        data = request.get_json(force=True, silent=False)
        
        if data is None:
            return jsonify({
                'success': False,
                'error': 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãŒç©ºã‹ã€JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£ã§ã™'
            }), 400
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
        required_fields = ['task_id', 'original_text', 'result_text', 'task_type',
                          'user_score', 'accuracy_score', 'fluency_score', 'completeness_score']
        
        for field in required_fields:
            if field not in data:
                return jsonify({
                    'success': False,
                    'error': f'å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ "{field}" ãŒã‚ã‚Šã¾ã›ã‚“'
                }), 400
        
        # å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚’å–å¾—
        learning_system = get_learning_system()
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®UTF-8ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        def clean_utf8_text(text):
            if not text:
                return ""
            # Unicodeåˆ¶å¾¡æ–‡å­—ã‚’é™¤å»
            import re
            cleaned = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f-\x9f]', '', str(text))
            return cleaned
        
        original_text = clean_utf8_text(data.get('original_text', ''))
        result_text = clean_utf8_text(data.get('result_text', ''))
        comment = clean_utf8_text(data.get('comment', ''))
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡
        feedback = learning_system.submit_feedback(
            task_id=str(data['task_id']),
            original_text=original_text,
            result_text=result_text,
            user_score=float(data['user_score']),
            accuracy_score=float(data['accuracy_score']),
            fluency_score=float(data['fluency_score']),
            completeness_score=float(data['completeness_score']),
            task_type=str(data['task_type']),
            user_feedback=comment if comment else None
        )
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
        metrics = learning_system.get_metrics()
        
        logger.info(f"âœ… ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å—ä¿¡: task_id={data['task_id']}, score={data['user_score']}")
        
        return jsonify({
            'success': True,
            'feedback_id': feedback.task_id,
            'total_feedbacks': metrics.total_tasks,
            'average_score': round(metrics.average_score, 2),
            'improvement_rate': round(metrics.improvement_rate, 2)
        })
        
    except KeyError as e:
        logger.error(f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸è¶³ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {str(e)}'
        }), 400
    except ValueError as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'ãƒ‡ãƒ¼ã‚¿å‹ãŒä¸æ­£ã§ã™: {str(e)}'
        }), 400
    except Exception as e:
        import traceback
        logger.error(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(traceback.format_exc())
        return jsonify({
            'success': False,
            'error': f'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500

@app.route('/api/learning-metrics', methods=['GET'])
def api_learning_metrics():
    """
    å­¦ç¿’ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—API - AIã‚¼ãƒŸç”¨
    ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ä½¿ç”¨
    """
    try:
        from services.apertus_learning_system import get_learning_system
        
        learning_system = get_learning_system()
        metrics = learning_system.get_metrics()
        
        return jsonify({
            'success': True,
            'metrics': {
                'total_tasks': metrics.total_tasks,
                'average_score': round(metrics.average_score, 2),
                'improvement_rate': round(metrics.improvement_rate, 2),
                'best_score': round(metrics.best_score, 2),
                'worst_score': round(metrics.worst_score, 2),
                'accuracy_trend': [round(s, 2) for s in metrics.accuracy_trend[-20:]],  # ç›´è¿‘20ä»¶
                'fluency_trend': [round(s, 2) for s in metrics.fluency_trend[-20:]]
            }
        })
        
    except Exception as e:
        logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500

@app.route('/settings')
def settings():
    """è¨­å®šãƒšãƒ¼ã‚¸"""
    return render_template('settings.html')

@app.route('/api/service-status')
def api_service_status():
    """AIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹API"""
    try:
        status = hf_service.get_status()
        return jsonify({
            'success': True,
            'service': status['service'],
            'model': status['model'],
            'available': status['available'],
            'device': status['device'],
            'api_key_required': status['api_key_required'],
            'completely_free': status['completely_free']
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/health-check')
def api_health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯API"""
    try:
        is_healthy = hf_service.available
        
        return jsonify({
            'success': is_healthy,
            'status': 'healthy' if is_healthy else 'unhealthy',
            'completely_free': True,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ===== å­¦ç¿’æ©Ÿèƒ½ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ =====

# ğŸ”¥ æ–°æ©Ÿèƒ½: ãƒãƒƒãƒå‡¦ç†API
@app.route('/api/batch-process', methods=['POST'])
def api_batch_process():
    """ãƒãƒƒãƒå‡¦ç†API - è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ‹¬å‡¦ç†"""
    try:
        if 'files' not in request.files:
            return jsonify({
                'success': False,
                'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        files = request.files.getlist('files')
        summary_mode = request.form.get('summary_mode', 'short')
        source_lang = request.form.get('source_lang', 'auto')
        target_lang = request.form.get('target_lang', 'jpn_Jpan')
        
        batch_id = str(uuid.uuid4())
        results = []
        total_files = len(files)
        completed = 0
        failed = 0
        
        start_time = time.time()
        
        logger.info(f"ğŸ“¦ ãƒãƒƒãƒå‡¦ç†é–‹å§‹: {total_files}ãƒ•ã‚¡ã‚¤ãƒ« (ID: {batch_id})")
        
        for i, file in enumerate(files):
            try:
                if file.filename == '':
                    failed += 1
                    continue
                
                if not allowed_file(file.filename):
                    results.append({
                        'filename': file.filename,
                        'success': False,
                        'error': 'å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™'
                    })
                    failed += 1
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                filename = secure_filename(file.filename)
                file_path = Config.UPLOAD_FOLDER / f"{uuid.uuid4()}_{filename}"
                file.save(file_path)
                
                # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                text = process_uploaded_file(file_path)
                
                # â­ Kaggle APIã§è¦ç´„å‡¦ç†
                if not kaggle_client or not kaggle_client.is_available():
                    results.append({
                        'filename': filename,
                        'success': False,
                        'error': 'AIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“'
                    })
                    failed += 1
                    file_path.unlink(missing_ok=True)
                    continue
                
                from config import get_language_name
                source_lang_name = get_language_name(source_lang)
                target_lang_name = get_language_name(target_lang, 'Japanese')
                
                kaggle_result = kaggle_client.summarize(
                    text=text,
                    max_length=400,
                    source_lang=source_lang_name,
                    target_lang=target_lang_name,
                    style='balanced',
                    summary_mode=summary_mode
                )
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                file_path.unlink(missing_ok=True)
                
                if kaggle_result and kaggle_result.get('success'):
                    summary = kaggle_result.get('summary', '')
                    results.append({
                        'filename': filename,
                        'success': True,
                        'summary': summary,
                        'original_length': len(text),
                        'summary_length': len(summary)
                    })
                    completed += 1
                else:
                    error_msg = kaggle_result.get('error', 'è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ') if kaggle_result else 'è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ'
                    results.append({
                        'filename': filename,
                        'success': False,
                        'error': error_msg
                    })
                    failed += 1
                
                logger.info(f"ğŸ“„ å‡¦ç†å®Œäº†: {i+1}/{total_files} - {filename}")
                
            except Exception as file_error:
                logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({file.filename}): {file_error}")
                results.append({
                    'filename': file.filename if file else 'unknown',
                    'success': False,
                    'error': str(file_error)
                })
                failed += 1
        
        total_time = time.time() - start_time
        
        # ãƒãƒƒãƒå±¥æ­´ã‚’ä¿å­˜
        try:
            db = get_db()
            db.save_batch_history(
                batch_id=batch_id,
                total_files=total_files,
                completed_files=completed,
                failed_files=failed,
                total_time=total_time,
                status='completed' if failed == 0 else 'partial' if completed > 0 else 'failed'
            )
        except Exception as db_error:
            logger.warning(f"âš ï¸ ãƒãƒƒãƒå±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {db_error}")
        
        logger.info(f"âœ… ãƒãƒƒãƒå‡¦ç†å®Œäº†: {completed}/{total_files}æˆåŠŸ, {failed}å¤±æ•— ({total_time:.1f}ç§’)")
        
        return jsonify({
            'success': True,
            'batch_id': batch_id,
            'total_files': total_files,
            'completed': completed,
            'failed': failed,
            'results': results,
            'total_time': total_time
        })
        
    except Exception as e:
        logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'ãƒãƒƒãƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500


# ğŸ”¥ æ–°æ©Ÿèƒ½: å…¨ãƒšãƒ¼ã‚¸ç¿»è¨³API
@app.route('/api/full-translate', methods=['POST'])
def api_full_translate():
    """PDFã®å…¨ãƒšãƒ¼ã‚¸ã‚’ç¿»è¨³"""
    try:
        data = request.get_json() if request.is_json else request.form
        text = data.get('text', '').strip()
        source_lang = data.get('source_lang', 'auto')
        target_lang = data.get('target_lang', 'jpn_Jpan')
        
        if not text:
            return jsonify({
                'success': False,
                'error': 'ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒšãƒ¼ã‚¸ã”ã¨ã«åˆ†å‰²ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚«ãƒ¼ã§åˆ¤å®šï¼‰
        pages = []
        current_page = []
        
        for line in text.split('\n'):
            if line.startswith('â”â”â”â”â” ãƒšãƒ¼ã‚¸'):
                if current_page:
                    pages.append('\n'.join(current_page))
                current_page = []
            else:
                current_page.append(line)
        
        if current_page:
            pages.append('\n'.join(current_page))
        
        logger.info(f"ğŸ“š å…¨ãƒšãƒ¼ã‚¸ç¿»è¨³é–‹å§‹: {len(pages)}ãƒšãƒ¼ã‚¸")
        
        translated_pages = []
        start_time = time.time()
        
        # â­ Kaggle APIã§ç¿»è¨³
        if not kaggle_client or not kaggle_client.is_available():
            return jsonify({
                'success': False,
                'error': 'AIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“'
            }), 503
        
        from config import get_language_name
        source_lang_name = get_language_name(source_lang)
        target_lang_name = get_language_name(target_lang, 'Japanese')
        
        for i, page_text in enumerate(pages):
            if not page_text.strip():
                continue
            
            # ãƒšãƒ¼ã‚¸ã”ã¨ã«Kaggle APIã§ç¿»è¨³
            kaggle_result = kaggle_client.summarize(
                text=page_text,
                max_length=2000,  # å…¨æ–‡ç¿»è¨³ãªã®ã§é•·ã‚
                source_lang=source_lang_name,
                target_lang=target_lang_name,
                style='narrative',
                summary_mode='long'
            )
            
            if kaggle_result and kaggle_result.get('success'):
                translated_pages.append(f"â”â”â”â”â” ãƒšãƒ¼ã‚¸ {i+1} â”â”â”â”â”\n{kaggle_result.get('summary', '')}")
                logger.info(f"âœ… ãƒšãƒ¼ã‚¸ {i+1}/{len(pages)} ç¿»è¨³å®Œäº†")
            else:
                translated_pages.append(f"â”â”â”â”â” ãƒšãƒ¼ã‚¸ {i+1} (ç¿»è¨³å¤±æ•—) â”â”â”â”â”\n{page_text}")
                logger.warning(f"âš ï¸ ãƒšãƒ¼ã‚¸ {i+1} ç¿»è¨³å¤±æ•—: {kaggle_result.get('error') if kaggle_result else 'ä¸æ˜'}")
        
        total_time = time.time() - start_time
        full_translated_text = '\n\n'.join(translated_pages)
        
        logger.info(f"ğŸ‰ å…¨ãƒšãƒ¼ã‚¸ç¿»è¨³å®Œäº†: {len(pages)}ãƒšãƒ¼ã‚¸ ({total_time:.1f}ç§’)")
        
        return jsonify({
            'success': True,
            'translated_text': full_translated_text,
            'total_pages': len(pages),
            'total_time': total_time,
            'original_length': len(text),
            'translated_length': len(full_translated_text)
        })
        
    except Exception as e:
        logger.error(f"å…¨ãƒšãƒ¼ã‚¸ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'å…¨ãƒšãƒ¼ã‚¸ç¿»è¨³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500


# â­ Kaggle APIç¿»è¨³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.route('/api/kaggle/translate', methods=['POST'])
def api_kaggle_translate():
    """Kaggle APIã‚’ä½¿ç”¨ã—ãŸç¿»è¨³"""
    try:
        if not kaggle_client:
            return jsonify({
                'success': False,
                'error': 'Kaggle APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“'
            }), 503
        
        if not kaggle_client.is_available():
            return jsonify({
                'success': False,
                'error': 'Kaggle APIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“'
            }), 503
        
        data = request.get_json() if request.is_json else request.form
        text = data.get('text', '').strip()
        source_lang = data.get('source_lang', 'English')
        target_lang = data.get('target_lang', 'Japanese')
        
        if not text:
            return jsonify({
                'success': False,
                'error': 'ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        logger.info(f"ğŸš€ Kaggleç¿»è¨³é–‹å§‹: {source_lang} â†’ {target_lang} ({len(text)}æ–‡å­—)")
        
        result = kaggle_client.translate(text, source_lang, target_lang)
        
        if result and result.get('success'):
            logger.info(f"âœ… Kaggleç¿»è¨³å®Œäº†: {result.get('time', 0):.1f}ç§’")
            return jsonify({
                'success': True,
                'translated_text': result.get('translation', ''),
                'processing_time': result.get('time', 0),
                'service': 'Kaggle Apertus-8B',
                'source_lang': source_lang,
                'target_lang': target_lang,
                'original_length': len(text),
                'translated_length': len(result.get('translation', ''))
            })
        else:
            error_msg = result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼') if result else 'å¿œç­”ãªã—'
            logger.error(f"âŒ Kaggleç¿»è¨³å¤±æ•—: {error_msg}")
            return jsonify({
                'success': False,
                'error': f'Kaggleç¿»è¨³å¤±æ•—: {error_msg}'
            }), 500
            
    except Exception as e:
        logger.error(f"Kaggleç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': f'Kaggleç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)}'
        }), 500


@app.route('/api/kaggle/status', methods=['GET'])
def api_kaggle_status():
    """Kaggle APIã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª"""
    try:
        if not kaggle_client:
            return jsonify({
                'available': False,
                'message': 'Kaggle APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'
            })
        
        is_available = kaggle_client.is_available(force_check=True)
        
        return jsonify({
            'available': is_available,
            'message': 'Kaggle APIã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™' if is_available else 'Kaggle APIã«æ¥ç¶šã§ãã¾ã›ã‚“',
            'url': kaggle_client.base_url if kaggle_client else None
        })
    except Exception as e:
        logger.error(f"Kaggleã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'available': False,
            'message': f'ã‚¨ãƒ©ãƒ¼: {str(e)}'
        })


# ğŸ”¥ æ–°æ©Ÿèƒ½: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸API
@app.route('/api/dictionary', methods=['GET'])
def api_get_dictionary():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã‚’å–å¾—"""
    try:
        db = get_db()
        source_lang = request.args.get('source_lang')
        target_lang = request.args.get('target_lang')
        
        dictionary = db.get_user_dictionary(source_lang, target_lang)
        
        return jsonify({
            'success': True,
            'dictionary': dictionary,
            'total': len(dictionary)
        })
    except Exception as e:
        logger.error(f"è¾æ›¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/dictionary', methods=['POST'])
def api_add_dictionary():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã«ç”¨èªã‚’è¿½åŠ """
    try:
        data = request.get_json()
        source_term = data.get('source_term', '').strip()
        target_term = data.get('target_term', '').strip()
        source_lang = data.get('source_lang', 'eng_Latn')
        target_lang = data.get('target_lang', 'jpn_Jpan')
        category = data.get('category', '')
        
        if not source_term or not target_term:
            return jsonify({
                'success': False,
                'error': 'ç”¨èªãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“'
            }), 400
        
        db = get_db()
        term_id = db.add_user_term(source_term, target_term, source_lang, target_lang, category)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–ã—ã¦æœ€æ–°è¾æ›¸ã‚’åæ˜ 
        hf_service.invalidate_dictionary_cache(source_lang=source_lang, target_lang=target_lang)
        
        return jsonify({
            'success': True,
            'message': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã«è¿½åŠ ã—ã¾ã—ãŸ',
            'term_id': term_id
        })
    except Exception as e:
        logger.error(f"è¾æ›¸è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/dictionary/<int:term_id>', methods=['DELETE'])
def api_delete_dictionary(term_id):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã‹ã‚‰ç”¨èªã‚’å‰Šé™¤"""
    try:
        db = get_db()
        success = db.delete_user_term(term_id)
        
        if success:
            hf_service.invalidate_dictionary_cache()
            return jsonify({
                'success': True,
                'message': 'ç”¨èªã‚’å‰Šé™¤ã—ã¾ã—ãŸ'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'ç”¨èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 404
    except Exception as e:
        logger.error(f"è¾æ›¸å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ğŸ”¥ æ–°æ©Ÿèƒ½: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å±¥æ­´API
@app.route('/api/db-history', methods=['GET'])
def api_db_history():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ç¿»è¨³å±¥æ­´ã‚’å–å¾—"""
    try:
        db = get_db()
        limit = int(request.args.get('limit', 50))
        offset = int(request.args.get('offset', 0))
        search = request.args.get('search', '')
        
        if search:
            history = db.search_translation_history(search)
        else:
            history = db.get_translation_history(limit, offset)
        
        return jsonify({
            'success': True,
            'history': history,
            'total': len(history)
        })
    except Exception as e:
        logger.error(f"å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/db-stats', methods=['GET'])
def api_db_stats():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    try:
        db = get_db()
        stats = db.get_statistics()
        
        return jsonify({
            'success': True,
            'stats': stats
        })
    except Exception as e:
        logger.error(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/batch-history', methods=['GET'])
def api_batch_history():
    """ãƒãƒƒãƒå‡¦ç†å±¥æ­´ã‚’å–å¾—"""
    try:
        db = get_db()
        limit = int(request.args.get('limit', 20))
        
        history = db.get_batch_history(limit)
        
        return jsonify({
            'success': True,
            'history': history,
            'total': len(history)
        })
    except Exception as e:
        logger.error(f"ãƒãƒƒãƒå±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# â­ ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼API
@app.route('/api/auth/register', methods=['POST'])
def api_register():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ²"""
    try:
        data = request.get_json()
        username = data.get('username', '').strip()
        password = data.get('password', '')
        email = data.get('email', '').strip()
        
        if not username or not password:
            return jsonify({'success': False, 'error': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯å¿…é ˆã§ã™'}), 400
        
        if len(password) < 6:
            return jsonify({'success': False, 'error': 'ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯6æ–‡å­—ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„'}), 400
        
        db = get_db()
        password_hash = hash_password(password)
        user_id = db.create_user(username, password_hash, email)
        
        if user_id is None:
            return jsonify({'success': False, 'error': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒæ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™'}), 409
        
        # è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³
        session['user_id'] = user_id
        session['username'] = username
        
        logger.info(f"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ²æˆåŠŸ: {username}")
        return jsonify({
            'success': True,
            'message': 'ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸ',
            'user': {'id': user_id, 'username': username}
        })
    except Exception as e:
        logger.error(f"âŒ ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/auth/login', methods=['POST'])
def api_login():
    """ãƒ­ã‚°ã‚¤ãƒ³"""
    try:
        data = request.get_json()
        username = data.get('username', '').strip()
        password = data.get('password', '')
        
        if not username or not password:
            return jsonify({'success': False, 'error': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„'}), 400
        
        db = get_db()
        user = db.get_user_by_username(username)
        
        if not user:
            return jsonify({'success': False, 'error': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}), 404
        
        password_hash = hash_password(password)
        if password_hash != user['password_hash']:
            return jsonify({'success': False, 'error': 'ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“'}), 401
        
        # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ
        session['user_id'] = user['id']
        session['username'] = user['username']
        db.update_user_login(user['id'])
        
        logger.info(f"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {username}")
        return jsonify({
            'success': True,
            'message': 'ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ',
            'user': {'id': user['id'], 'username': user['username']}
        })
    except Exception as e:
        logger.error(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/auth/logout', methods=['POST'])
def api_logout():
    """ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"""
    username = session.get('username', 'Unknown')
    session.clear()
    logger.info(f"ğŸ‘‹ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ: {username}")
    return jsonify({'success': True, 'message': 'ãƒ­ã‚°ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ'})


@app.route('/api/auth/status', methods=['GET'])
def api_auth_status():
    """ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ç¢ºèª"""
    if 'user_id' in session:
        return jsonify({
            'logged_in': True,
            'user': {
                'id': session['user_id'],
                'username': session['username']
            }
        })
    else:
        return jsonify({'logged_in': False})


# ========================================
# ğŸ‡¨ğŸ‡­ Apertuså­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ API
# ========================================

# â­ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—é€šçŸ¥é–¢æ•°
def send_progress(task_id: str, stage: str, progress: int, message: str):
    """
    WebSocketã§é€²æ—çŠ¶æ³ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
    
    Args:
        task_id: ã‚¿ã‚¹ã‚¯ID
        stage: å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸ (extract, translate, summarize, etc.)
        progress: é€²æ—ç‡ (0-100)
        message: é€²æ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    try:
        socketio.emit('progress_update', {
            'task_id': task_id,
            'stage': stage,
            'progress': progress,
            'message': message,
            'timestamp': time.time()
        })
        logger.info(f"ğŸ“¡ é€²æ—é€ä¿¡ [{task_id}] {stage}: {progress}% - {message}")
    except Exception as e:
        logger.warning(f"âš ï¸ é€²æ—é€ä¿¡å¤±æ•—: {e}")

# â­ WebSocketã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
@socketio.on('connect')
def handle_connect():
    """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šæ™‚"""
    logger.info(f"ğŸ”Œ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š: {request.sid}")

@socketio.on('disconnect')
def handle_disconnect():
    """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ‡æ–­æ™‚"""
    logger.info(f"ğŸ”Œ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ‡æ–­: {request.sid}")


if __name__ == '__main__':
    print("\n" + "="*60)
    print("ğŸš€ recapisure - é«˜æ€§èƒ½å¤šè¨€èªè¦ç´„ã‚µãƒ¼ãƒ“ã‚¹ (Apertus-8Bç‰ˆ)")
    print("="*60)
    print("âœ¨ æ©Ÿèƒ½:")
    print("   ğŸ“ é•·æ–‡è¦ç´„ - å¤§é‡ãƒ†ã‚­ã‚¹ãƒˆã®åŠ¹ç‡çš„è¦ç´„ (ç®‡æ¡æ›¸ãæ•´å½¢å¯¾å¿œ)")
    print("   ğŸ“ˆ çŸ­æ–‡å±•é–‹ - çŸ­æ–‡ã‚’è©³ç´°ãªé•·æ–‡ã«å¤‰æ›")
    print("   ğŸŒ URLè¦ç´„ - Webè¨˜äº‹ã®è‡ªå‹•å–å¾—ï¼‹è¦ç´„")
    print("   ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ - TXT, MD, PDF, ç”»åƒ (OCR)")
    print("   ğŸ“¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º")
    print("="*60)
    
    # Kaggle Apertus-8Bã®çŠ¶æ…‹ç¢ºèª
    if kaggle_client and kaggle_client.is_available():
        print(f"âœ… Kaggle Apertus-8B æ¥ç¶šæˆåŠŸ")
        print(f"ğŸ¯ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: swiss-ai/Apertus-8B-Instruct-2509")
        print(f"ğŸŒ å¯¾å¿œè¨€èª: 1,811è¨€èª")
        print(f"ğŸ’° å®Œå…¨ç„¡æ–™ãƒ»APIã‚­ãƒ¼ä¸è¦!")
    else:
        print("âš ï¸  Kaggle Apertus-8B ã«æ¥ç¶šã§ãã¾ã›ã‚“")
        print("ğŸ’¡ Kaggle Notebookã‚’èµ·å‹•ã—ã¦ãã ã•ã„")
        print("   è©³ç´°: KAGGLE_NGROK_SETUP.md ã‚’å‚ç…§")
    
    print("="*60)
    print("ğŸŒ http://localhost:5000 ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½")
    print("â¹ï¸  åœæ­¢ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    print("="*60 + "\n")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç§»è¡Œã®ãŸã‚ï¼‰
    @app.before_request
    def clear_old_session_history():
        """å¤ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ï¼ˆCookieã‚µã‚¤ã‚ºåˆ¶é™å¯¾ç­–ï¼‰"""
        if 'history' in session:
            session.pop('history', None)
            session.modified = True
    
    # SocketIOå¯¾å¿œã®å®Ÿè¡Œ (use_reloader=False: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ã®è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–)
    socketio.run(app, host='127.0.0.1', port=5000, debug=True, use_reloader=False, allow_unsafe_werkzeug=True)
